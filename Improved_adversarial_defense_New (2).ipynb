{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T00:56:31.06263Z",
          "iopub.status.busy": "2026-02-19T00:56:31.062414Z",
          "iopub.status.idle": "2026-02-19T00:56:31.069201Z",
          "shell.execute_reply": "2026-02-19T00:56:31.068536Z",
          "shell.execute_reply.started": "2026-02-19T00:56:31.062607Z"
        },
        "id": "Iy9GFoBo-LUD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2026-02-19T00:56:37.18756Z",
          "iopub.status.busy": "2026-02-19T00:56:37.186829Z",
          "iopub.status.idle": "2026-02-19T00:56:37.190876Z",
          "shell.execute_reply": "2026-02-19T00:56:37.190265Z",
          "shell.execute_reply.started": "2026-02-19T00:56:37.187535Z"
        },
        "id": "MlbrhawV-LT1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T00:56:41.721384Z",
          "iopub.status.busy": "2026-02-19T00:56:41.72112Z",
          "iopub.status.idle": "2026-02-19T00:56:46.741926Z",
          "shell.execute_reply": "2026-02-19T00:56:46.741159Z",
          "shell.execute_reply.started": "2026-02-19T00:56:41.721364Z"
        },
        "id": "Ud-u2G9L-LUE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#!pip -q install sentence-transformers thop statsmodels\n",
        "!pip -q install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2026-02-19T00:56:54.299585Z",
          "iopub.status.busy": "2026-02-19T00:56:54.298784Z",
          "iopub.status.idle": "2026-02-19T00:57:30.493349Z",
          "shell.execute_reply": "2026-02-19T00:57:30.492686Z",
          "shell.execute_reply.started": "2026-02-19T00:56:54.299552Z"
        },
        "id": "jC_0UNgiDzAM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gcsfs fsspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-19T00:57:38.710161Z",
          "iopub.status.busy": "2026-02-19T00:57:38.709796Z",
          "iopub.status.idle": "2026-02-19T00:57:42.202352Z",
          "shell.execute_reply": "2026-02-19T00:57:42.201647Z",
          "shell.execute_reply.started": "2026-02-19T00:57:38.710134Z"
        },
        "id": "wiGQ6acD-LUH",
        "outputId": "88782798-d635-44a5-fa15-1a29c99d3504",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#!pip -q install Datasets\n",
        "# At the very top of your notebook\n",
        "!pip install -q datasets transformers torch torchvision torchaudio\n",
        "!pip install -q textattack nltk tqdm\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T00:57:54.459604Z",
          "iopub.status.busy": "2026-02-19T00:57:54.459032Z",
          "iopub.status.idle": "2026-02-19T00:57:59.372725Z",
          "shell.execute_reply": "2026-02-19T00:57:59.372036Z",
          "shell.execute_reply.started": "2026-02-19T00:57:54.459577Z"
        },
        "id": "hvMif-glKa9e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q GPUtil psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-02-19T00:58:03.882667Z",
          "iopub.status.busy": "2026-02-19T00:58:03.882376Z"
        },
        "id": "Zy1z7OZ8Ka9g",
        "outputId": "387b56da-d479-4d65-b845-d7a42fa5d326",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# Imports and Setup\n",
        "# ====\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import psutil\n",
        "import GPUtil\n",
        "import threading\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "import warnings\n",
        "\n",
        "# Cell A: ablation config & run-id builder (insert right after imports)\n",
        "import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "\n",
        "# ====\n",
        "# Dataset Preparation\n",
        "# ====\n",
        "\n",
        "# Download NLTK data if needed\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK data (wordnet, stopwords)...\")\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "\n",
        "print(\"Loading SST-2 dataset from Hugging Face...\")\n",
        "sst2_dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.dataset_stats = {\n",
        "            'total_samples': len(texts),\n",
        "            'avg_text_length': np.mean([len(str(text).split()) for text in texts[:1000]]),\n",
        "            'label_distribution': np.bincount(labels) if labels else None\n",
        "        }\n",
        "        print(f\"Dataset initialized with {self.dataset_stats['total_samples']} samples\")\n",
        "        print(f\"Average text length: {self.dataset_stats['avg_text_length']:.1f} words\")\n",
        "        if self.dataset_stats['label_distribution'] is not None:\n",
        "            print(f\"Label distribution: {dict(enumerate(self.dataset_stats['label_distribution']))}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[int(idx)])\n",
        "        label = int(self.labels[int(idx)])\n",
        "        try:\n",
        "            encoding = self.tokenizer(\n",
        "                text,\n",
        "                max_length=self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Tokenization error for sample {idx}: {e}\")\n",
        "            encoding = self.tokenizer(\n",
        "                \"\",\n",
        "                max_length=self.max_length,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "# ====\n",
        "# Optimized Hyperparameters for SST-2\n",
        "# ====\n",
        "batch_size = 64          # Double the batch size (DistilBERT is light, this fits easily)\n",
        "max_length = 48          # Reduced from 128. 99% of SST-2 sentences are < 45 tokens.\n",
        "max_epochs = 5           # 10 is too many for SST-2; it usually converges by epoch 3.\n",
        "learning_rate = 2e-5     # Standard for DistilBERT\n",
        "accumulation_steps = 1   # With batch_size 64, you don't need accumulation on most GPUs\n",
        "\n",
        "train_dataset = SentimentDataset(\n",
        "    sst2_dataset['train']['sentence'],\n",
        "    sst2_dataset['train']['label'],\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "val_dataset = SentimentDataset(\n",
        "    sst2_dataset['validation']['sentence'],\n",
        "    sst2_dataset['validation']['label'],\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "np.random.seed(42)\n",
        "# Use 80% of available training data (53,879 samples)\n",
        "# Keep all validation data (872 samples)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ====\n",
        "# Proper Train/Val/Test Split\n",
        "# ====\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"\\n=== Creating Proper Train/Val/Test Split ===\")\n",
        "\n",
        "# NEW CODE (FIXED)\n",
        "all_texts = list(sst2_dataset['train']['sentence']) + list(sst2_dataset['validation']['sentence'])\n",
        "all_labels = list(sst2_dataset['train']['label']) + list(sst2_dataset['validation']['label'])\n",
        "\n",
        "print(f\"Total samples available: {len(all_texts)}\")\n",
        "\n",
        "# Split: 80% train, 10% val, 10% test (stratified to maintain class balance)\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    all_texts,\n",
        "    all_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts,\n",
        "    temp_labels,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_labels\n",
        ")\n",
        "\n",
        "print(f\"\\nSplit sizes:\")\n",
        "print(f\"  Train: {len(train_texts)} samples ({len(train_texts)/len(all_texts)*100:.1f}%)\")\n",
        "print(f\"  Val: {len(val_texts)} samples ({len(val_texts)/len(all_texts)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_texts)} samples ({len(test_texts)/len(all_texts)*100:.1f}%)\")\n",
        "\n",
        "# Check class distribution\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(f\"  Train - Negative: {train_labels.count(0)} ({train_labels.count(0)/len(train_labels)*100:.1f}%), Positive: {train_labels.count(1)} ({train_labels.count(1)/len(train_labels)*100:.1f}%)\")\n",
        "print(f\"  Val   - Negative: {val_labels.count(0)} ({val_labels.count(0)/len(val_labels)*100:.1f}%), Positive: {val_labels.count(1)} ({val_labels.count(1)/len(val_labels)*100:.1f}%)\")\n",
        "print(f\"  Test  - Negative: {test_labels.count(0)} ({test_labels.count(0)/len(test_labels)*100:.1f}%), Positive: {test_labels.count(1)} ({test_labels.count(1)/len(test_labels)*100:.1f}%)\")\n",
        "\n",
        "# Create datasets\n",
        "print(\"\\nCreating datasets...\")\n",
        "train_dataset = SentimentDataset(\n",
        "    train_texts,\n",
        "    train_labels,\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "val_dataset = SentimentDataset(\n",
        "    val_texts,\n",
        "    val_labels,\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "test_dataset = SentimentDataset(\n",
        "    test_texts,\n",
        "    test_labels,\n",
        "    tokenizer,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "print(\"Creating dataloaders...\")\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "print(f\"\\n=== Dataset Summary ===\")\n",
        "print(f\"Train samples: {len(train_loader.dataset)}\")\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n",
        "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Max length: {max_length}\")\n",
        "print(f\"Effective batch size (with accumulation): {batch_size * 2}\")\n",
        "print(f\"\\nSetup complete! Ready for training.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:04.899362Z",
          "iopub.status.busy": "2025-08-12T22:54:04.898776Z",
          "iopub.status.idle": "2025-08-12T22:54:04.916384Z",
          "shell.execute_reply": "2025-08-12T22:54:04.915819Z",
          "shell.execute_reply.started": "2025-08-12T22:54:04.899339Z"
        },
        "id": "akDV7zGLUyBW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import collections.abc\n",
        "\n",
        "\n",
        "# Small helper: build run id from config dict\n",
        "def build_run_id_from_cfg(cfg):\n",
        "    bits = ['BASE']\n",
        "    if cfg.get(\"no_adv\"):    bits.append('noAdv')\n",
        "    if cfg.get(\"no_smooth\"): bits.append('noSmooth')\n",
        "    if cfg.get(\"tag\"):       bits.append(cfg[\"tag\"])\n",
        "    return '_'.join(bits)\n",
        "\n",
        "# Results aggregator path (match your notebook paths)\n",
        "RESULTS_PATH = Path(\"results/aggregate.json\")\n",
        "RESULTS_PATH.parent.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Safe logger that appends run results in aggregate.json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "\n",
        "def sanitize_for_json(obj):\n",
        "    # dict-like\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: sanitize_for_json(v) for k, v in obj.items()}\n",
        "    # lists / tuples\n",
        "    if isinstance(obj, (list, tuple)):\n",
        "        return [sanitize_for_json(v) for v in obj]\n",
        "    # numpy scalars\n",
        "    if isinstance(obj, (np.integer,)):\n",
        "        return int(obj)\n",
        "    if isinstance(obj, (np.floating,)):\n",
        "        return float(obj)\n",
        "    if isinstance(obj, np.bool_):\n",
        "        return bool(obj)\n",
        "    if isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    # pandas types\n",
        "    if isinstance(obj, pd.Timestamp):\n",
        "        return obj.isoformat()\n",
        "    if isinstance(obj, pd.Series):\n",
        "        return sanitize_for_json(obj.to_dict())\n",
        "    if isinstance(obj, pd.DataFrame):\n",
        "        return sanitize_for_json(obj.to_dict(orient=\"list\"))\n",
        "    # datetimes\n",
        "    if isinstance(obj, (datetime.datetime, datetime.date)):\n",
        "        return obj.isoformat()\n",
        "    # fallback for other types exposing .item()\n",
        "    try:\n",
        "        if hasattr(obj, \"item\"):\n",
        "            val = obj.item()\n",
        "            # If item() returns numpy scalar, sanitize recursively\n",
        "            return sanitize_for_json(val)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return obj  # assume it's already JSON-serializable\n",
        "\n",
        "def log_run(run_id, stats, results_path=\"aggregate.json\"):\n",
        "    # load existing results (if any)\n",
        "    if os.path.exists(results_path):\n",
        "        try:\n",
        "            with open(results_path, \"r\") as f:\n",
        "                results = json.load(f)\n",
        "        except Exception:\n",
        "            results = {}\n",
        "    else:\n",
        "        results = {}\n",
        "    # sanitize stats so json.dump won't fail on numpy/pandas objects\n",
        "    results[run_id] = sanitize_for_json(stats)\n",
        "    with open(results_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"✔ Logged {run_id} to {results_path}\")\n",
        "\n",
        "# Default ablation matrix (4-run mini-ablation)\n",
        "RUN_MATRIX = [\n",
        "    {\"no_adv\": False, \"no_smooth\": False, \"tag\": \"\"},           # BASE\n",
        "    {\"no_adv\": True,  \"no_smooth\": False, \"tag\": \"noAdv\"},     # no adversarial training\n",
        "    {\"no_adv\": False, \"no_smooth\": True,  \"tag\": \"noSmooth\"},  # no smoothing\n",
        "    {\"no_adv\": True,  \"no_smooth\": True,  \"tag\": \"noAdv_noSmooth\"}  # both off\n",
        "]\n",
        "\n",
        "\n",
        "# Create directories for saving results and plots\n",
        "RESULTS_DIR = Path('results')\n",
        "PLOTS_DIR = Path('plots')\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "PLOTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def now_tag():\n",
        "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "def flatten_dict(d, parent_key='', sep='_'):\n",
        "    \"\"\"\n",
        "    Flattens a nested dictionary, joining keys with a separator.\n",
        "    It skips lists to avoid excessively long columns (e.g., epoch-by-epoch history).\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = parent_key + sep + k if parent_key else k\n",
        "        if isinstance(v, collections.abc.MutableMapping):\n",
        "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
        "        # Exclude lists from being flattened into the CSV\n",
        "        elif not isinstance(v, list):\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)\n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# Define the path for the new comprehensive CSV results file\n",
        "ALL_RUNS_CSV_PATH = RESULTS_DIR / \"all_runs_results.csv\"\n",
        "\n",
        "def log_run_csv(run_id, stats_dict):\n",
        "    \"\"\"\n",
        "    Logs the results of a single run to a comprehensive CSV file.\n",
        "    \"\"\"\n",
        "    # Add the run_id to the dictionary for logging\n",
        "    log_data = {'run_id': run_id}\n",
        "    log_data.update(stats_dict)\n",
        "\n",
        "    # Flatten the dictionary to make it CSV-friendly\n",
        "    flat_data = flatten_dict(log_data)\n",
        "\n",
        "    # Check if the file exists to determine if we need to write headers\n",
        "    file_exists = os.path.isfile(ALL_RUNS_CSV_PATH)\n",
        "\n",
        "    try:\n",
        "        with open(ALL_RUNS_CSV_PATH, 'a', newline='') as f:\n",
        "            # Use DictWriter to handle headers and data rows easily\n",
        "            writer = csv.DictWriter(f, fieldnames=flat_data.keys())\n",
        "\n",
        "            if not file_exists:\n",
        "                writer.writeheader()  # Write headers only if the file is new\n",
        "\n",
        "            writer.writerow(flat_data)\n",
        "\n",
        "        print(f\"✔ Logged {run_id} to {ALL_RUNS_CSV_PATH}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error logging {run_id} to CSV: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:04.917722Z",
          "iopub.status.busy": "2025-08-12T22:54:04.917097Z",
          "iopub.status.idle": "2025-08-12T22:54:04.938079Z",
          "shell.execute_reply": "2025-08-12T22:54:04.937434Z",
          "shell.execute_reply.started": "2025-08-12T22:54:04.917702Z"
        },
        "id": "3bx4jQo2awy5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Directory to save checkpoints (using a relative path for portability)\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, loss, filename=\"checkpoint.pth\"):\n",
        "    \"\"\"Saves the model checkpoint.\"\"\"\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, filename)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\", device='cpu'):\n",
        "    \"\"\"Loads the model checkpoint if it exists.\"\"\"\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, filename)\n",
        "    start_epoch = 0\n",
        "    if os.path.isfile(checkpoint_path):\n",
        "        print(f\"Loading checkpoint '{checkpoint_path}'\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"=> loaded checkpoint '{filename}' (resuming from epoch {start_epoch})\")\n",
        "    else:\n",
        "        print(f\"=> no checkpoint found at '{checkpoint_path}', starting from scratch.\")\n",
        "    return start_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:04.940907Z",
          "iopub.status.busy": "2025-08-12T22:54:04.940678Z",
          "iopub.status.idle": "2025-08-12T22:54:04.973871Z",
          "shell.execute_reply": "2025-08-12T22:54:04.973112Z",
          "shell.execute_reply.started": "2025-08-12T22:54:04.94089Z"
        },
        "id": "w6o1_MvNLYX4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# Hybrid Attack Generator: Original Performance + Modern Monitoring\n",
        "# ===================================================\n",
        "\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Get synonyms for a word using WordNet\"\"\"\n",
        "    synonyms = set()\n",
        "    try:\n",
        "        for syn in wordnet.synsets(word):\n",
        "            for lemma in syn.lemmas():\n",
        "                synonym = lemma.name().replace('_', ' ')\n",
        "                if synonym != word:\n",
        "                    synonyms.add(synonym)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return list(synonyms)\n",
        "\n",
        "class AdversarialAttackGenerator:\n",
        "    \"\"\"\n",
        "    Enhanced attack generator that matches the original high-performing implementation\n",
        "    with sophisticated word importance calculation and entropy-based synonym selection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, device):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.stopwords = set(stopwords.words('english'))\n",
        "\n",
        "        # Original neutral words for insertion attacks\n",
        "        self.neutral_words = [\n",
        "            'basically', 'literally', 'actually', 'really', 'quite', 'simply',\n",
        "            'nearly', 'almost', 'essentially', 'truly', 'absolutely', 'somewhat'\n",
        "        ]\n",
        "\n",
        "        # Original character substitutions\n",
        "        self.char_subs = {'a': '@', 'e': '3', 'i': '1', 'o': '0', 's': '$', 'l': '1'}\n",
        "\n",
        "        # Attack statistics\n",
        "        self.attack_stats = {\n",
        "            'synonym_calls': 0,\n",
        "            'character_calls': 0,\n",
        "            'insertion_calls': 0,\n",
        "            'mixed_calls': 0,\n",
        "            'total_time': 0.0\n",
        "        }\n",
        "\n",
        "    def _validate_text(self, text):\n",
        "        \"\"\"Validate that text is not empty and has reasonable content\"\"\"\n",
        "        if not text or not text.strip():\n",
        "            return False\n",
        "        words = text.split()\n",
        "        if len(words) < 2:\n",
        "            return False\n",
        "        if not any(c.isalpha() for c in text):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def _get_word_importance(self, text, label):\n",
        "        \"\"\"\n",
        "        Calculate word importance using gradient-based scoring.\n",
        "        This is the key difference from the simplified version.\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        words = text.split()\n",
        "\n",
        "        if len(words) < 3:\n",
        "            return random.choice(range(len(words))) if words else 0\n",
        "\n",
        "        max_drop, best_idx = -float('inf'), -1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Get original prediction probability\n",
        "            encoding = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "            original_logits = self.model(encoding['input_ids'], encoding['attention_mask'])\n",
        "            original_prob = F.softmax(original_logits, dim=1)[0, label].item()\n",
        "\n",
        "            # Test importance of each word by removal\n",
        "            for i, word in enumerate(words):\n",
        "                if word.lower() in self.stopwords:\n",
        "                    continue\n",
        "\n",
        "                # Create text without this word\n",
        "                temp_text = ' '.join(words[:i] + words[i+1:])\n",
        "                encoding = self.tokenizer(temp_text, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "                temp_logits = self.model(encoding['input_ids'], encoding['attention_mask'])\n",
        "                temp_prob = F.softmax(temp_logits, dim=1)[0, label].item()\n",
        "\n",
        "                # Calculate probability drop (importance)\n",
        "                drop = original_prob - temp_prob\n",
        "                if drop > max_drop:\n",
        "                    max_drop, best_idx = drop, i\n",
        "\n",
        "        return best_idx if best_idx != -1 else random.choice(range(len(words)))\n",
        "\n",
        "    def _synonym_attack(self, text, label):\n",
        "        \"\"\"\n",
        "        Sophisticated synonym attack using entropy-based selection.\n",
        "        This selects the synonym that maximizes model uncertainty.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        idx_to_replace = self._get_word_importance(text, label)\n",
        "        original_word = words[idx_to_replace]\n",
        "        synonyms = get_synonyms(original_word)\n",
        "\n",
        "        if not synonyms or (len(synonyms) == 1 and synonyms[0] == original_word):\n",
        "            return text\n",
        "\n",
        "        best_synonym, max_entropy = original_word, -1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for synonym in synonyms:\n",
        "                temp_words = words[:]\n",
        "                temp_words[idx_to_replace] = synonym\n",
        "                temp_text = ' '.join(temp_words)\n",
        "\n",
        "                encoding = self.tokenizer(temp_text, return_tensors='pt', padding=True, truncation=True).to(self.device)\n",
        "                logits = self.model(encoding['input_ids'], encoding['attention_mask'])\n",
        "                probs = F.softmax(logits, dim=1)\n",
        "\n",
        "                # Calculate entropy (model uncertainty)\n",
        "                entropy = -torch.sum(probs * torch.log(probs + 1e-9)).item()\n",
        "\n",
        "                if entropy > max_entropy:\n",
        "                    max_entropy, best_synonym = entropy, synonym\n",
        "\n",
        "        words[idx_to_replace] = best_synonym\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def _character_attack(self, text):\n",
        "        \"\"\"\n",
        "        Character-level perturbations with 20% word perturbation rate.\n",
        "        Uses multiple operations: swap, insert, delete, substitute.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        num_words_to_perturb = max(1, int(len(words) * 0.2))  # Original 20% rate\n",
        "\n",
        "        candidate_indices = [\n",
        "            i for i, word in enumerate(words)\n",
        "            if len(word) > 2 and word.lower() not in self.stopwords\n",
        "        ]\n",
        "\n",
        "        if not candidate_indices:\n",
        "            return text\n",
        "\n",
        "        indices_to_perturb = random.sample(candidate_indices, min(num_words_to_perturb, len(candidate_indices)))\n",
        "\n",
        "        for i in indices_to_perturb:\n",
        "            word = words[i]\n",
        "            op = random.choice(['swap', 'insert', 'delete', 'substitute'])\n",
        "\n",
        "            if op == 'swap' and len(word) > 1:\n",
        "                idx = random.randint(0, len(word) - 2)\n",
        "                words[i] = word[:idx] + word[idx+1] + word[idx] + word[idx+2:]\n",
        "            elif op == 'insert':\n",
        "                idx = random.randint(0, len(word))\n",
        "                words[i] = word[:idx] + random.choice(string.ascii_lowercase) + word[idx:]\n",
        "            elif op == 'delete' and len(word) > 1:\n",
        "                idx = random.randint(0, len(word) - 1)\n",
        "                words[i] = word[:idx] + word[idx+1:]\n",
        "            elif op == 'substitute' and len(word) > 0:\n",
        "                idx = random.randint(0, len(word) - 1)\n",
        "                char = word[idx]\n",
        "                if char.lower() in self.char_subs:\n",
        "                    words[i] = word[:idx] + self.char_subs[char.lower()] + word[idx+1:]\n",
        "\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def _insertion_attack(self, text):\n",
        "        \"\"\"\n",
        "        Insertion attack with 15% insertion rate using neutral words.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        num_insertions = random.randint(1, max(2, int(len(words) * 0.15)))  # Original 15% rate\n",
        "\n",
        "        for _ in range(num_insertions):\n",
        "            insert_pos = random.randint(0, len(words))\n",
        "            words.insert(insert_pos, random.choice(self.neutral_words))\n",
        "\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def generate(self, texts, labels, attack_type='mixed'):\n",
        "        \"\"\"\n",
        "        Generate adversarial examples with the original sophisticated logic.\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        adv_texts = []\n",
        "\n",
        "        for text, label in zip(texts, labels):\n",
        "            try:\n",
        "                if attack_type == 'synonym':\n",
        "                    adv_text = self._synonym_attack(text, label)\n",
        "                    self.attack_stats['synonym_calls'] += 1\n",
        "                elif attack_type == 'character':\n",
        "                    adv_text = self._character_attack(text)\n",
        "                    self.attack_stats['character_calls'] += 1\n",
        "                elif attack_type == 'insertion':\n",
        "                    adv_text = self._insertion_attack(text)\n",
        "                    self.attack_stats['insertion_calls'] += 1\n",
        "                elif attack_type == 'mixed':\n",
        "                    # Original mixed attack logic\n",
        "                    chosen_attack = random.choice([\n",
        "                        lambda t, l: self._synonym_attack(t, l),\n",
        "                        lambda t, l: self._character_attack(t),\n",
        "                        lambda t, l: self._insertion_attack(t)\n",
        "                    ])\n",
        "                    adv_text = chosen_attack(text, label)\n",
        "                    self.attack_stats['mixed_calls'] += 1\n",
        "                else:\n",
        "                    adv_text = text\n",
        "\n",
        "                # Validate the generated text\n",
        "                if self._validate_text(adv_text):\n",
        "                    adv_texts.append(adv_text)\n",
        "                else:\n",
        "                    # Fallback to original text if generation failed\n",
        "                    adv_texts.append(text)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attack generation failed for text: {text[:50]}... Error: {e}\")\n",
        "                adv_texts.append(text)  # Fallback to original\n",
        "\n",
        "        self.attack_stats['total_time'] += time.time() - start_time\n",
        "        return adv_texts\n",
        "\n",
        "    def augment_batch_with_adversarial_examples(self, batch, augmentation_ratio=0.6, attack_type='mixed'):\n",
        "        \"\"\"\n",
        "        Augments a batch with adversarial examples. This method is crucial for adversarial training.\n",
        "        \"\"\"\n",
        "        input_ids = batch['input_ids']\n",
        "        labels = batch['labels']\n",
        "        attention_mask = batch['attention_mask']\n",
        "\n",
        "        num_samples = input_ids.shape[0]\n",
        "        num_to_augment = int(augmentation_ratio * num_samples)\n",
        "\n",
        "        if num_to_augment == 0:\n",
        "            return input_ids, attention_mask, labels\n",
        "\n",
        "        # Select a random subset of samples to augment\n",
        "        indices_to_augment = np.random.choice(num_samples, num_to_augment, replace=False)\n",
        "        indices_clean = np.array([i for i in range(num_samples) if i not in indices_to_augment])\n",
        "\n",
        "        input_ids_to_augment = input_ids[indices_to_augment]\n",
        "        labels_to_augment = labels[indices_to_augment]\n",
        "\n",
        "        # Decode tokens to text to generate attacks\n",
        "        texts_to_augment = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids_to_augment]\n",
        "\n",
        "        # Generate adversarial texts using the existing 'generate' method\n",
        "        adv_texts = self.generate(texts_to_augment, labels_to_augment.tolist(), attack_type=attack_type)\n",
        "\n",
        "        # Re-tokenize the generated adversarial texts\n",
        "        adv_encodings = self.tokenizer(\n",
        "            adv_texts,\n",
        "            max_length=input_ids.shape[1],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # --- FIX: Move the new tensors to the correct device ---\n",
        "        adv_input_ids = adv_encodings['input_ids'].to(self.device)\n",
        "        adv_attention_mask = adv_encodings['attention_mask'].to(self.device)\n",
        "        # --- End of FIX ---\n",
        "\n",
        "        # Combine the original clean examples with the new adversarial ones\n",
        "        combined_input_ids = torch.cat((input_ids[indices_clean], adv_input_ids), dim=0)\n",
        "        combined_attention_mask = torch.cat((attention_mask[indices_clean], adv_attention_mask), dim=0)\n",
        "        combined_labels = torch.cat((labels[indices_clean], labels_to_augment), dim=0)\n",
        "\n",
        "        # Shuffle the combined batch\n",
        "        shuffle_indices = torch.randperm(combined_input_ids.shape[0])\n",
        "\n",
        "        return (\n",
        "            combined_input_ids[shuffle_indices],\n",
        "            combined_attention_mask[shuffle_indices],\n",
        "            combined_labels[shuffle_indices]\n",
        "        )\n",
        "\n",
        "    def get_attack_stats(self):\n",
        "        \"\"\"Get attack generation statistics\"\"\"\n",
        "        return self.attack_stats.copy()\n",
        "\n",
        "    def reset_stats(self):\n",
        "        \"\"\"Reset attack statistics\"\"\"\n",
        "        self.attack_stats = {\n",
        "            'synonym_calls': 0,\n",
        "            'character_calls': 0,\n",
        "            'insertion_calls': 0,\n",
        "            'mixed_calls': 0,\n",
        "            'total_time': 0.0\n",
        "        }\n",
        "\n",
        "    def generate_adversarial_examples(self, input_ids, labels, model, num_examples=None, attack_type='mixed', reference_len=128):\n",
        "        \"\"\"\n",
        "        Generates adversarial examples for a given batch. This method is called by evaluate_model_robustness.\n",
        "        It decodes tokens, calls the internal generate method, and re-tokenizes.\n",
        "        \"\"\"\n",
        "        if num_examples is None:\n",
        "            num_examples = input_ids.shape[0]\n",
        "\n",
        "        # Decode tokens to text\n",
        "        texts_to_attack = [self.tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids[:num_examples]]\n",
        "        labels_to_attack = labels[:num_examples].tolist()\n",
        "\n",
        "        # Generate adversarial texts\n",
        "        adv_texts = self.generate(texts_to_attack, labels_to_attack, attack_type=attack_type)\n",
        "\n",
        "        # Re-tokenize\n",
        "        adv_encodings = self.tokenizer(\n",
        "            adv_texts,\n",
        "            max_length=reference_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return adv_encodings['input_ids'].to(self.device), adv_encodings['attention_mask'].to(self.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:04.974805Z",
          "iopub.status.busy": "2025-08-12T22:54:04.974546Z",
          "iopub.status.idle": "2025-08-12T22:54:04.999899Z",
          "shell.execute_reply": "2025-08-12T22:54:04.999246Z",
          "shell.execute_reply.started": "2025-08-12T22:54:04.974789Z"
        },
        "id": "gbvdkZCgKa9n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# Model Definitions with Resource Tracking\n",
        "# ====\n",
        "\n",
        "class ModelWithResourceTracking(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.inference_times = []\n",
        "\n",
        "    def forward_with_timing(self, *args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = self.forward(*args, **kwargs)\n",
        "        inference_time = time.time() - start_time\n",
        "        self.inference_times.append(inference_time)\n",
        "        return result\n",
        "\n",
        "    def get_model_size(self):\n",
        "        param_size = sum(p.numel() * p.element_size() for p in self.parameters())\n",
        "        buffer_size = sum(b.numel() * b.element_size() for b in self.buffers())\n",
        "        return (param_size + buffer_size) / 1024 / 1024  # MB\n",
        "\n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "# Vanilla DistilBERT\n",
        "class VanillaDistilBERT(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2, dropout_rate=0.4):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, num_classes)\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "        cls_embedding = self.dropout(cls_embedding)\n",
        "        return self.classifier(cls_embedding)\n",
        "\n",
        "\n",
        "# Adversarial Training Model\n",
        "class AdversarialTrainingModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2, dropout_rate=0.4):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, num_classes)\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "        cls_embedding = self.dropout(cls_embedding)\n",
        "        return self.classifier(cls_embedding)\n",
        "\n",
        "\n",
        "# Defensive Distillation Model\n",
        "class DefensiveDistillationModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2, dropout_rate=0.4, temperature=3.0):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.distilbert.config.hidden_size, num_classes)\n",
        "        self.temperature = temperature  # Store temperature\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "        cls_embedding = self.dropout(cls_embedding)\n",
        "        logits = self.classifier(cls_embedding)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        return logits / self.temperature\n",
        "\n",
        "\n",
        "# Input Preprocessing Model\n",
        "class InputPreprocessingModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.denoiser = nn.Sequential(\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 768)\n",
        "        )\n",
        "        self.classifier = nn.Linear(768, num_classes)\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        denoised = self.denoiser(embeddings)\n",
        "        return self.classifier(denoised)\n",
        "\n",
        "\n",
        "# Ensemble Defense Model\n",
        "class EnsembleDefenseModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2, num_models=3):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleList([\n",
        "            VanillaDistilBERT(num_classes) for _ in range(num_models)\n",
        "        ])\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Use the first model's embeddings\"\"\"\n",
        "        return self.models[0].get_input_embeddings()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            output = model(input_ids=input_ids, attention_mask=attention_mask, inputs_embeds=inputs_embeds)\n",
        "            outputs.append(output)\n",
        "        return torch.mean(torch.stack(outputs), dim=0)\n",
        "\n",
        "\n",
        "# Original HAT-D Model Components\n",
        "class OriginalDenoisingNetwork(nn.Module):\n",
        "    def __init__(self, hidden_dim=512):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(768, 640),\n",
        "            nn.LayerNorm(640),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(640, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 640),\n",
        "            nn.LayerNorm(640),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(640, 768)\n",
        "        )\n",
        "        self.residual_scale = nn.Parameter(torch.tensor(0.3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return torch.tanh(identity + self.residual_scale * x)\n",
        "\n",
        "\n",
        "class OriginalHybridDefenseModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.denoising = OriginalDenoisingNetwork()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "        embeddings = self.denoising(embeddings)\n",
        "        return self.classifier(embeddings)\n",
        "\n",
        "\n",
        "# Enhanced HAT-D Model Components\n",
        "class CharacterCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim=768, num_filters=192, kernel_sizes=[2, 3, 4, 5]):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embedding_dim, num_filters, k, padding=(k-1)//2)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.bn = nn.BatchNorm1d(len(kernel_sizes) * num_filters)\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        conved = [F.relu(conv(x)) for conv in self.convs]\n",
        "        pooled = [F.adaptive_max_pool1d(conv, 1).squeeze(2) for conv in conved]\n",
        "        cat = torch.cat(pooled, dim=1)\n",
        "        cat = self.bn(cat)\n",
        "        cat = self.dropout(cat)\n",
        "        return self.fc(cat)\n",
        "\n",
        "\n",
        "class SequenceAttention(nn.Module):\n",
        "    def __init__(self, embedding_dim=768, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        key_padding_mask = (attention_mask == 0)\n",
        "        attn_output, _ = self.attention(x, x, x, key_padding_mask=key_padding_mask)\n",
        "        return attn_output\n",
        "\n",
        "\n",
        "class EnhancedHATDModel(ModelWithResourceTracking):\n",
        "    def __init__(self, num_classes=2, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.embedding_dim = 768\n",
        "\n",
        "        # Unfreeze last two layers + pooler (FIXED INDENTATION)\n",
        "        for name, param in self.distilbert.named_parameters():\n",
        "            if any(layer in name for layer in [\"transformer.layer.4\", \"transformer.layer.5\", \"pooler\"]):\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Defense components\n",
        "        self.insertion_defense = SequenceAttention(self.embedding_dim, 4)\n",
        "        self.character_defense = CharacterCNN(self.embedding_dim, 128)\n",
        "        self.denoiser = OriginalDenoisingNetwork()\n",
        "\n",
        "        # Fusion gate\n",
        "        self.fusion_gate = nn.Sequential(\n",
        "            nn.Linear(768 * 2, 768),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, 384),\n",
        "            nn.LayerNorm(384),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(384, num_classes)\n",
        "        )\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        \"\"\"Required for TRADES loss and smoothing penalty\"\"\"\n",
        "        return self.distilbert.embeddings.word_embeddings\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
        "        if inputs_embeds is not None:\n",
        "            outputs = self.distilbert(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
        "        else:\n",
        "            outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_embeddings = outputs.last_hidden_state\n",
        "\n",
        "        # Apply defenses\n",
        "        attended_embeddings = self.insertion_defense(sequence_embeddings, attention_mask)\n",
        "        insertion_features = attended_embeddings[:, 0, :]\n",
        "        character_features = self.character_defense(sequence_embeddings)\n",
        "\n",
        "        # Gated fusion\n",
        "        concat = torch.cat((insertion_features, character_features), dim=1)\n",
        "        gate = self.fusion_gate(concat)\n",
        "        fused = gate * insertion_features + (1 - gate) * character_features\n",
        "\n",
        "        return self.classifier(fused)\n",
        "\n",
        "\n",
        "# Model registry for easy instantiation\n",
        "MODEL_REGISTRY = {\n",
        "    'Vanilla_DistilBERT': VanillaDistilBERT,\n",
        "    'Adversarial_Training': AdversarialTrainingModel,\n",
        "    'Defensive_Distillation': DefensiveDistillationModel,\n",
        "    'Input_Preprocessing': InputPreprocessingModel,\n",
        "    'Ensemble_Defense': EnsembleDefenseModel,\n",
        "    'Original_HAT-D': OriginalHybridDefenseModel,\n",
        "    'Enhanced_HAT-D': EnhancedHATDModel\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ec39f1c76ddc48ebb61757f4941479c2",
            "9807b53008f4423eb8c92ff54547c8de",
            "496027e5e60842cb94b03fecadee185d",
            "8cbaeac1dc1e4d6d82affeaabdd1b73a",
            "f0f430ef3ad6491b90d27424e5c72142",
            "cb58ffdf6b54478baa6940a5e8174c13",
            "fb4a2ecd04dd4567b17ef1ba75ce1f04",
            "5d92c02c36fd4d969a354cde2d233ae5",
            "3bb0c823a01b4d06b29a2da5255acdaf",
            "99b8eed724d64a6c9188b2f5b01a8c08",
            "1f2aacf4f22c4fe38a132b7c85b25c43",
            "3e61ba0d871146748adc7ea67804d3bf",
            "66aae913dd094097953b3bef0b1ca5e1",
            "4d0b873c198345fbba1478c8aa97aa54",
            "f06358380d314ccdb4532c5611087234",
            "beeae42109eb489398ec5c229bfc2401",
            "b1b43360ef004dea99f92e0e3be54f78",
            "3218dce3db324ea483ca6024575942c6",
            "1f3b9fd2e9ee45c99a65d44efd137063",
            "6effd6612f314bbdad068d0ed28bed09",
            "565ce116571d4d5d98f61a9ed895b537",
            "4841187dc2e641a39b12fa6d107aa3f4",
            "adc7de544f054987b429fe97e7c85d50",
            "50107308a63547feb1f721d03e93fcdf",
            "2de4897d014042b1a1ec0f8cc21a3e8c",
            "0624abb3290f4a1dbec1d6550084f1f0",
            "904ef3caf03a4c4d9fd7d5aa63b09333",
            "760e0badad1042c8991685544a202cc1",
            "0261364a0de54921b8871c367b257d05",
            "20d5b2a758f04fba915fe004f62261ab",
            "e2ee09607d8f4ceb9f3eb1480e65548e",
            "ff666dfe54554d949fabfa92ae61d95b",
            "09fa72dc6bf4460da1c28802527d4ad3",
            "909c51de2a9742b49e9803c854f36af2",
            "aebeef71f70a4a90b1274a3866d4c9a3",
            "009c746b8da443c5b7fc807fa4eab37e",
            "de669a8b011a4718ab79babe18f7c9c5",
            "30a988cf82e84a0f855f7b43488c5164",
            "7c76c0bb2aef4232b77c9e2efddc05ec",
            "ec157ce6fa974b10a01ac7b03faefcf4",
            "2481f5718d644960b7d083b041076048",
            "6fa38b76988c49128f9e3d1049ac4fd7",
            "6b2e2c3a947b4429969a38d92e91fe7f",
            "b9caacc57ab94af7a1b808895326464b",
            "faa69fa5c5934a628a44f5bf2a5741b4",
            "460cfefe390d4c209dc8b2ceea90cbe6",
            "01833589d8174c0e9c24824381313436",
            "6379298fb54e447595e28d75c494d5e7",
            "6efb45b8cf8d4fe7a2b7e0952c9d3391",
            "a708debe447d41f49c68bfb2117aed1f",
            "ea59b90d760f4d25814c44aea9e886c7",
            "c8b6e2bc13144d8e83cc815b875a3823",
            "17d3d114fe354a46ab47d865e3b923de",
            "63b87c6b27044fe49870779eeb94a34d",
            "fdcd821d146146e295d2b0273b95eaf6",
            "26166625a3c14813b6f7f8961b5ba884",
            "f21cb963a1bc41068b2ab6d392041ea9",
            "8503e1d19cb34ab58a03e06e1c377f5c",
            "8f0710d336ed4588aa73f8385e572252",
            "043c5005ab934728aaf5f0e0e14074fc",
            "3bc9f7e6bd5a4cf0b0b6551acdf9755c",
            "a50fe74b2fa24d48bfa50cc183dca8c2",
            "f8ef30b925b74dcf94a8afe64a2411fc",
            "94b208da3c754628ad72f42e1cb6bbd2",
            "81f1c3507b8d4a389170945d5f3e95cc",
            "3c555de0f1e14f66b94126b6c297356b",
            "26e88827fe324cc08fac525dfd222bee",
            "42d25d9fa09b4ea2871284ef727d1881",
            "70c95616a2d44fd39a73d6e06ea09d62",
            "3a04f8cfbe5d4f20a1acf705d4b93af6",
            "f3493971a3ec4fe89bd052e579849ab6",
            "f2625452a5a446798232e44bbea7fcc3",
            "0da10c6cc8274e13b082ccb95f498fdb",
            "dab65d31746a41e9a024195ff9d5630a",
            "fec2dda4d12f4371a6979dad010fb766",
            "60ffdc2cd3154346aaf8e00cddf5fd45",
            "7066896be3f241e1b9df52293412b449",
            "7188bad121b84373b8c8d315314a816b",
            "5818af3b25aa45c2acfc4972585e5814",
            "b85ea876297f4f1dbad2b4d2cbf2fa15",
            "f7e4b70831204722becd8bcc7c5e50f0",
            "22923d6762f046e99ec8cb5c6017c851",
            "638ee0856e6d4372a7c3a9eb0a4037f3",
            "b77437d1688b4c43b021450d40bcd873",
            "3a4c4c80b54d4dfe8e0b447ca3ddeb00",
            "d0feab5e353a40719ae403ce185b2c27",
            "6a605d59cd364e3284f4b1ac11d1fd2c",
            "1efb562ee1e045d2b256eca5bf491776",
            "117a92ccde0e46a7b527d6c3215a4004",
            "8e66e8d5cf29461a8c8f899ba60ef2d8",
            "4f5ce4f7f9d243ae9d1aff9c934d1142",
            "53e4d027d755416aa6cb90be3521a5a0",
            "121e8adc40d74dbc9b7604835921f0ea",
            "e7c2ee7780f8401aa377a56e7a13d1f7",
            "187808e3801a49209c4866b39a53346a",
            "6a9170e05e7040bf9f94de49d1b111b5",
            "5434974f9ce04e428b535a771ed340b1",
            "97d0582d832948d6b83ed0eaf095bf91",
            "01d3468e05cc4c7bb70e6b97025ba0c9"
          ]
        },
        "id": "L28EvDc0i0KO",
        "outputId": "f578fbba-44a0-410e-db97-2fc2c6dcbe0a"
      },
      "outputs": [],
      "source": [
        "# Test all models\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for model_name, model_class in MODEL_REGISTRY.items():\n",
        "    print(f\"\\nTesting {model_name}...\")\n",
        "\n",
        "    try:\n",
        "        # Instantiate model\n",
        "        model = model_class(num_classes=2).to(device)\n",
        "\n",
        "        # Test get_input_embeddings\n",
        "        embeddings = model.get_input_embeddings()\n",
        "        print(f\"  ✓ get_input_embeddings() works: {embeddings.weight.shape}\")\n",
        "\n",
        "        # Test forward with input_ids\n",
        "        dummy_input_ids = torch.randint(0, 1000, (2, 128)).to(device)\n",
        "        dummy_attention_mask = torch.ones(2, 128).to(device)\n",
        "        output = model(input_ids=dummy_input_ids, attention_mask=dummy_attention_mask)\n",
        "        print(f\"  ✓ forward(input_ids) works: {output.shape}\")\n",
        "\n",
        "        # Test forward with inputs_embeds\n",
        "        dummy_embeds = embeddings(dummy_input_ids)\n",
        "        output = model(inputs_embeds=dummy_embeds, attention_mask=dummy_attention_mask)\n",
        "        print(f\"  ✓ forward(inputs_embeds) works: {output.shape}\")\n",
        "\n",
        "        print(f\"  ✓ {model_name} passed all tests!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ {model_name} FAILED: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.000937Z",
          "iopub.status.busy": "2025-08-12T22:54:05.000723Z",
          "iopub.status.idle": "2025-08-12T22:54:05.018996Z",
          "shell.execute_reply": "2025-08-12T22:54:05.018093Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.000921Z"
        },
        "id": "xP00k-GzNcjo",
        "outputId": "ab6d1b43-98e7-4be8-fb30-21003cd80dee",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Print 5 random sentences with their labels\n",
        "import random\n",
        "\n",
        "random_indices = random.sample(range(len(train_dataset)), 5)\n",
        "for idx in random_indices:\n",
        "    text = train_dataset.texts[idx]\n",
        "    label = train_dataset.labels[idx]\n",
        "    print(f\"Text: {text}\\nLabel: {label}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.020167Z",
          "iopub.status.busy": "2025-08-12T22:54:05.019912Z",
          "iopub.status.idle": "2025-08-12T22:54:05.032901Z",
          "shell.execute_reply": "2025-08-12T22:54:05.03226Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.02014Z"
        },
        "id": "D6mkKvNCKa9q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# Resource Monitoring and Latency Tracking\n",
        "# ====\n",
        "\n",
        "class ResourceMonitor:\n",
        "    def __init__(self):\n",
        "        self.monitoring = False\n",
        "        self.metrics = defaultdict(list)\n",
        "        self.monitor_thread = None\n",
        "        self.epoch_start_time = None\n",
        "        self.epoch_metrics = {}\n",
        "\n",
        "    def start_epoch_monitoring(self):\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.epoch_metrics = {\n",
        "            'cpu_percent': [],\n",
        "            'memory_percent': [],\n",
        "            'memory_mb': [],\n",
        "            'gpu_memory_mb': [],\n",
        "            'gpu_utilization': []\n",
        "        }\n",
        "        self.monitoring = True\n",
        "        self.monitor_thread = threading.Thread(target=self._monitor_resources)\n",
        "        self.monitor_thread.daemon = True\n",
        "        self.monitor_thread.start()\n",
        "\n",
        "    def end_epoch_monitoring(self):\n",
        "        self.monitoring = False\n",
        "        if self.monitor_thread and self.monitor_thread.is_alive():\n",
        "            self.monitor_thread.join(timeout=1.0)\n",
        "\n",
        "        epoch_summary = {}\n",
        "        if self.epoch_metrics['cpu_percent']:\n",
        "            epoch_summary['cpu_percent_avg'] = np.mean(self.epoch_metrics['cpu_percent'])\n",
        "            epoch_summary['cpu_percent_max'] = np.max(self.epoch_metrics['cpu_percent'])\n",
        "        else:\n",
        "            epoch_summary['cpu_percent_avg'] = 0\n",
        "            epoch_summary['cpu_percent_max'] = 0\n",
        "\n",
        "        if self.epoch_metrics['memory_mb']:\n",
        "            epoch_summary['memory_mb_avg'] = np.mean(self.epoch_metrics['memory_mb'])\n",
        "            epoch_summary['memory_mb_max'] = np.max(self.epoch_metrics['memory_mb'])\n",
        "        else:\n",
        "            epoch_summary['memory_mb_avg'] = 0\n",
        "            epoch_summary['memory_mb_max'] = 0\n",
        "\n",
        "        if self.epoch_metrics['gpu_memory_mb']:\n",
        "            epoch_summary['gpu_memory_mb'] = np.max(self.epoch_metrics['gpu_memory_mb'])\n",
        "            epoch_summary['gpu_memory_mb_avg'] = np.mean(self.epoch_metrics['gpu_memory_mb'])\n",
        "        else:\n",
        "            epoch_summary['gpu_memory_mb'] = 0\n",
        "            epoch_summary['gpu_memory_mb_avg'] = 0\n",
        "\n",
        "        if self.epoch_metrics['gpu_utilization']:\n",
        "            epoch_summary['gpu_utilization_avg'] = np.mean(self.epoch_metrics['gpu_utilization'])\n",
        "            epoch_summary['gpu_utilization_max'] = np.max(self.epoch_metrics['gpu_utilization'])\n",
        "        else:\n",
        "            epoch_summary['gpu_utilization_avg'] = 0\n",
        "            epoch_summary['gpu_utilization_max'] = 0\n",
        "\n",
        "        if self.epoch_start_time:\n",
        "            epoch_summary['epoch_duration'] = time.time() - self.epoch_start_time\n",
        "        else:\n",
        "            epoch_summary['epoch_duration'] = 0\n",
        "\n",
        "        return epoch_summary\n",
        "\n",
        "    def _monitor_resources(self):\n",
        "        while self.monitoring:\n",
        "            try:\n",
        "                cpu_percent = psutil.cpu_percent(interval=0.1)\n",
        "                memory = psutil.virtual_memory()\n",
        "                memory_mb = memory.used / (1024 * 1024)\n",
        "\n",
        "                self.epoch_metrics['cpu_percent'].append(cpu_percent)\n",
        "                self.epoch_metrics['memory_percent'].append(memory.percent)\n",
        "                self.epoch_metrics['memory_mb'].append(memory_mb)\n",
        "\n",
        "                try:\n",
        "                    gpus = GPUtil.getGPUs()\n",
        "                    if gpus:\n",
        "                        gpu = gpus[0]\n",
        "                        gpu_memory_mb = gpu.memoryUsed\n",
        "                        gpu_utilization = gpu.load * 100\n",
        "\n",
        "                        self.epoch_metrics['gpu_memory_mb'].append(gpu_memory_mb)\n",
        "                        self.epoch_metrics['gpu_utilization'].append(gpu_utilization)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            except Exception:\n",
        "                pass\n",
        "            time.sleep(0.1)\n",
        "# Initialize the global resource monitor\n",
        "resource_monitor = ResourceMonitor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-18T23:52:50.457997Z",
          "iopub.status.busy": "2026-02-18T23:52:50.457527Z",
          "iopub.status.idle": "2026-02-18T23:52:50.49714Z",
          "shell.execute_reply": "2026-02-18T23:52:50.495841Z",
          "shell.execute_reply.started": "2026-02-18T23:52:50.457968Z"
        },
        "id": "66nSikS2Ka9r",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# MODIFIED FOR CHECKPOINTING + GRADIENT ACCUMULATION\n",
        "# ===\n",
        "# Training Function\n",
        "# ===\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "            return False\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def trades_loss(model,\n",
        "                input_ids,\n",
        "                attention_mask,\n",
        "                labels,\n",
        "                device,\n",
        "                beta=1.0,\n",
        "                epsilon=0.03,\n",
        "                alpha=0.01,\n",
        "                num_iter=5):\n",
        "    \"\"\"\n",
        "    Calculates the TRADES loss, which balances standard cross-entropy with a robustness term.\n",
        "    This function generates adversarial examples internally via PGD on the embedding space.\n",
        "    \"\"\"\n",
        "    outputs_clean = model(input_ids, attention_mask=attention_mask)\n",
        "    logits_clean = outputs_clean.logits if hasattr(outputs_clean, 'logits') else outputs_clean\n",
        "    loss_ce = F.cross_entropy(logits_clean, labels)\n",
        "\n",
        "    if not hasattr(model, 'get_input_embeddings'):\n",
        "        return loss_ce\n",
        "\n",
        "    embedding_layer = model.get_input_embeddings()\n",
        "    inputs_embeds = embedding_layer(input_ids).detach()\n",
        "    delta = torch.zeros_like(inputs_embeds, requires_grad=True).to(device)\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        perturbed_embeds = inputs_embeds + delta\n",
        "        outputs_adv = model(inputs_embeds=perturbed_embeds, attention_mask=attention_mask)\n",
        "        logits_adv = outputs_adv.logits if hasattr(outputs_adv, 'logits') else outputs_adv\n",
        "        loss_kl_attack = F.kl_div(\n",
        "            F.log_softmax(logits_adv, dim=1),\n",
        "            F.softmax(logits_clean.detach(), dim=1),\n",
        "            reduction='sum'\n",
        "        )\n",
        "        loss_kl_attack.backward()\n",
        "        delta.data = delta.data + alpha * torch.sign(delta.grad.detach())\n",
        "        delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
        "        delta.grad.zero_()\n",
        "\n",
        "    perturbed_embeds = (inputs_embeds + delta).detach()\n",
        "    outputs_adv = model(inputs_embeds=perturbed_embeds, attention_mask=attention_mask)\n",
        "    logits_adv = outputs_adv.logits if hasattr(outputs_adv, 'logits') else outputs_adv\n",
        "    loss_kl_robustness = F.kl_div(\n",
        "        F.log_softmax(logits_adv, dim=1),\n",
        "        F.softmax(logits_clean, dim=1),\n",
        "        reduction='batchmean'\n",
        "    )\n",
        "    total_loss = loss_ce + beta * loss_kl_robustness\n",
        "    return total_loss\n",
        "\n",
        "def _default_smoothing_penalty(logits, lam=1e-4):\n",
        "    return lam * torch.mean(logits.pow(2))\n",
        "\n",
        "def randomized_smoothing_penalty(model, input_ids, attention_mask, logits,\n",
        "                                 num_samples=2, sigma=0.08, lam=1e-2, temp=1.0,\n",
        "                                 reduction='mean', device=None):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    if not hasattr(model, \"get_input_embeddings\"):\n",
        "        return _default_smoothing_penalty(logits, lam=lam)\n",
        "\n",
        "    try:\n",
        "        emb_layer = model.get_input_embeddings()\n",
        "        inputs_embeds = emb_layer(input_ids)\n",
        "    except Exception:\n",
        "        return _default_smoothing_penalty(logits, lam=lam)\n",
        "\n",
        "    noisy_logits = []\n",
        "    for _ in range(max(1, num_samples)):\n",
        "        noise = torch.randn_like(inputs_embeds, device=inputs_embeds.device) * sigma\n",
        "        noisy_embeds = inputs_embeds + noise\n",
        "        try:\n",
        "            out_noisy = model(inputs_embeds=noisy_embeds, attention_mask=attention_mask)\n",
        "            logits_noisy = out_noisy.logits if hasattr(out_noisy, 'logits') else out_noisy\n",
        "        except Exception:\n",
        "            return _default_smoothing_penalty(logits, lam=lam)\n",
        "        noisy_logits.append(logits_noisy)\n",
        "\n",
        "    noisy_stack = torch.stack(noisy_logits, dim=0)\n",
        "    noisy_mean = noisy_stack.mean(dim=0)\n",
        "\n",
        "    logp_clean = F.log_softmax(logits / temp, dim=-1)\n",
        "    p_noisy = F.softmax(noisy_mean / temp, dim=-1)\n",
        "    kl_per_batch = F.kl_div(logp_clean, p_noisy, reduction='batchmean')\n",
        "    loss = lam * kl_per_batch\n",
        "    if reduction == 'mean':\n",
        "        return loss\n",
        "    elif reduction == 'sum':\n",
        "        return loss * logits.shape[0]\n",
        "    else:\n",
        "        return loss\n",
        "\n",
        "def train_model_comprehensive(\n",
        "    model, model_name, train_loader, val_loader, epochs=max_epochs,\n",
        "    use_adversarial=False, attack_generator=None, augmentation_ratio=0.65,\n",
        "    attack_type='mixed', cfg=None, smoothing_penalty_fn=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Comprehensive training function with modular structure, improved clarity, and robust error handling.\n",
        "    Includes gradient accumulation, cosine annealing with warm restarts, and AMP (Mixed Precision).\n",
        "    \"\"\"\n",
        "    if cfg is None:\n",
        "        cfg = {}\n",
        "    if smoothing_penalty_fn is None:\n",
        "        smoothing_penalty_fn = _default_smoothing_penalty\n",
        "\n",
        "    effective_use_adv = bool(use_adversarial) and (not cfg.get(\"no_adv\", False))\n",
        "    apply_smoothing = (not cfg.get(\"no_smooth\", False))\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {model_name} | cfg={cfg} | use_adversarial(effectively)={effective_use_adv}, smoothing={apply_smoothing}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-3)\n",
        "\n",
        "    # ── AMP scaler (no-op on CPU) ──────────────────────────────────────────\n",
        "    use_amp = torch.cuda.is_available()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "    if use_amp:\n",
        "        print(f\"  ⚡ AMP (Mixed Precision) enabled\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  AMP disabled (no CUDA device found)\")\n",
        "\n",
        "    # === CHECKPOINTING: LOAD STATE IF EXISTS ===\n",
        "    checkpoint_filename = f\"{model.__class__.__name__}_{model_name}.pth\"\n",
        "    start_epoch = load_checkpoint(model, optimizer, filename=checkpoint_filename, device=device)\n",
        "    # === END CHECKPOINTING ===\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Cosine Annealing with Warm Restarts\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    early_stopper = EarlyStopper(patience=3, min_delta=0.001)\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
        "        'epoch_times': [], 'learning_rates': [], 'resource_usage': []\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Gradient accumulation for effective larger batch size\n",
        "    accumulation_steps = 2  # effective batch size × 2\n",
        "\n",
        "    # === CHECKPOINTING: UPDATE LOOP TO START FROM SAVED EPOCH ===\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        resource_monitor.start_epoch_monitoring()\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Initialize gradients once per epoch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]', leave=False)\n",
        "        for batch_idx, batch in enumerate(train_pbar):\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['label'].to(device)\n",
        "\n",
        "                if effective_use_adv:\n",
        "                    # TRADES loss does its own internal backward passes (PGD),\n",
        "                    # so we keep it outside autocast to avoid fp16 instability\n",
        "                    loss = trades_loss(model, input_ids, attention_mask, labels, device=device, beta=4.0)\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "                        predictions = torch.argmax(logits, dim=1)\n",
        "                        correct = (predictions == labels).sum().item()\n",
        "                        total = len(labels)\n",
        "                else:\n",
        "                    # ── AMP autocast for standard forward pass ─────────────\n",
        "                    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "                        ce_loss = criterion(logits, labels)\n",
        "\n",
        "                        smoothing_loss = 0.0\n",
        "                        if apply_smoothing and smoothing_penalty_fn is not None:\n",
        "                            smoothing_loss = smoothing_penalty_fn(\n",
        "                                model, input_ids, attention_mask, logits,\n",
        "                                num_samples=3, sigma=0.1, lam=0.05, device=device\n",
        "                            )\n",
        "\n",
        "                        loss = ce_loss + smoothing_loss\n",
        "\n",
        "                    predictions = torch.argmax(logits, dim=1)\n",
        "                    correct = (predictions == labels).sum().item()\n",
        "                    total = len(labels)\n",
        "\n",
        "                # Gradient accumulation: scale loss via AMP scaler\n",
        "                loss = loss / accumulation_steps\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                # Only update weights every accumulation_steps batches\n",
        "                if (batch_idx + 1) % accumulation_steps == 0:\n",
        "                    scaler.unscale_(optimizer)   # ← required before grad clip\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                # Unscale loss for logging\n",
        "                train_loss += loss.item() * accumulation_steps\n",
        "                train_correct += correct\n",
        "                train_total += total\n",
        "\n",
        "                current_acc = 100. * train_correct / train_total if train_total > 0 else 0.0\n",
        "                train_pbar.set_postfix({\n",
        "                    'Loss': f'{train_loss/(batch_idx+1):.4f}',\n",
        "                    'Acc': f'{current_acc:.2f}%'\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in training batch {batch_idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Handle any remaining accumulated gradients at epoch end\n",
        "        if (batch_idx + 1) % accumulation_steps != 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # ---------- validation pass ---------------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]', leave=False)\n",
        "            for batch_idx, batch in enumerate(val_pbar):\n",
        "                try:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['label'].to(device)\n",
        "\n",
        "                    with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                        logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "                        loss = criterion(logits, labels)\n",
        "                    predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += len(labels)\n",
        "\n",
        "                    current_acc = 100. * val_correct / val_total if val_total > 0 else 0.0\n",
        "                    val_pbar.set_postfix({\n",
        "                        'Loss': f'{val_loss/(batch_idx+1):.4f}',\n",
        "                        'Acc': f'{current_acc:.2f}%'\n",
        "                    })\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in validation batch {batch_idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        epoch_resources = resource_monitor.end_epoch_monitoring()\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        train_loss_avg = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
        "        train_acc = train_correct / train_total if train_total > 0 else 0.0\n",
        "        val_loss_avg = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
        "        val_acc = val_correct / val_total if val_total > 0 else 0.0\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        history['train_loss'].append(train_loss_avg)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss_avg)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['epoch_times'].append(epoch_time)\n",
        "        history['learning_rates'].append(current_lr)\n",
        "        history['resource_usage'].append(epoch_resources)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"  Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
        "        print(f\"  Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
        "        print(f\"  Time: {epoch_time:.2f}s, LR: {current_lr:.2e}\")\n",
        "        print(f\"  GPU Memory: {epoch_resources.get('gpu_memory_mb', 0):.1f}MB\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            print(f\"  ✓ New best validation accuracy: {val_acc*100:.2f}%\")\n",
        "\n",
        "        # === CHECKPOINTING: SAVE STATE AFTER EACH EPOCH ===\n",
        "        save_checkpoint(model, optimizer, epoch, val_loss_avg, filename=checkpoint_filename)\n",
        "        # === END CHECKPOINTING ===\n",
        "\n",
        "        # Step scheduler (no argument needed for CosineAnnealingWarmRestarts)\n",
        "        scheduler.step()\n",
        "\n",
        "        if early_stopper.early_stop(val_loss_avg):\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        if epoch % 2 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        model.to(device)\n",
        "        print(f\"\\nLoaded best model with validation accuracy: {best_val_acc*100:.2f}%\")\n",
        "\n",
        "    history['best_val_acc'] = best_val_acc\n",
        "    history['total_epochs'] = len(history['train_loss'])\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7gOUBubMh43"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# def trades_loss(\n",
        "#     model,\n",
        "#     input_ids,\n",
        "#     attention_mask,\n",
        "#     labels,\n",
        "#     device,\n",
        "#     beta=1.0,\n",
        "#     epsilon=0.03,\n",
        "#     alpha=0.01,\n",
        "#     num_iter=5,\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Calculates the TRADES loss, which balances standard cross-entropy with a robustness term.\n",
        "#     This function generates adversarial examples internally via PGD on the embedding space.\n",
        "#     \"\"\"\n",
        "#     outputs_clean = model(input_ids, attention_mask=attention_mask)\n",
        "#     logits_clean = outputs_clean.logits if hasattr(outputs_clean, 'logits') else outputs_clean\n",
        "#     loss_ce = F.cross_entropy(logits_clean, labels)\n",
        "\n",
        "#     if not hasattr(model, 'get_input_embeddings'):\n",
        "#         return loss_ce\n",
        "\n",
        "#     embedding_layer = model.get_input_embeddings()\n",
        "#     inputs_embeds = embedding_layer(input_ids).detach()\n",
        "#     delta = torch.zeros_like(inputs_embeds, requires_grad=True).to(device)\n",
        "\n",
        "#     for _ in range(num_iter):\n",
        "#         perturbed_embeds = inputs_embeds + delta\n",
        "#         outputs_adv = model(inputs_embeds=perturbed_embeds, attention_mask=attention_mask)\n",
        "#         logits_adv = outputs_adv.logits if hasattr(outputs_adv, 'logits') else outputs_adv\n",
        "#         loss_kl_attack = F.kl_div(\n",
        "#             F.log_softmax(logits_adv, dim=1),\n",
        "#             F.softmax(logits_clean.detach(), dim=1),\n",
        "#             reduction='sum'\n",
        "#         )\n",
        "#         loss_kl_attack.backward()\n",
        "#         delta.data = delta.data + alpha * torch.sign(delta.grad.detach())\n",
        "#         delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
        "#         delta.grad.zero_()\n",
        "\n",
        "#     perturbed_embeds = (inputs_embeds + delta).detach()\n",
        "#     outputs_adv = model(inputs_embeds=perturbed_embeds, attention_mask=attention_mask)\n",
        "#     logits_adv = outputs_adv.logits if hasattr(outputs_adv, 'logits') else outputs_adv\n",
        "#     loss_kl_robustness = F.kl_div(\n",
        "#         F.log_softmax(logits_adv, dim=1),\n",
        "#         F.softmax(logits_clean, dim=1),\n",
        "#         reduction='batchmean'\n",
        "#     )\n",
        "#     total_loss = loss_ce + beta * loss_kl_robustness\n",
        "#     return total_loss\n",
        "\n",
        "# def _default_smoothing_penalty(logits, lam=1e-4):\n",
        "#     return lam * torch.mean(logits.pow(2))\n",
        "\n",
        "# def randomized_smoothing_penalty(\n",
        "#     model, input_ids, attention_mask, logits,\n",
        "#     num_samples=2, sigma=0.08, lam=1e-2, temp=1.0,\n",
        "#     reduction='mean', device=None\n",
        "# ):\n",
        "#     if device is None:\n",
        "#         device = next(model.parameters()).device\n",
        "\n",
        "#     if not hasattr(model, \"get_input_embeddings\"):\n",
        "#         return _default_smoothing_penalty(logits, lam=lam)\n",
        "\n",
        "#     try:\n",
        "#         emb_layer = model.get_input_embeddings()\n",
        "#         inputs_embeds = emb_layer(input_ids)\n",
        "#     except Exception:\n",
        "#         return _default_smoothing_penalty(logits, lam=lam)\n",
        "\n",
        "#     noisy_logits = []\n",
        "#     for _ in range(max(1, num_samples)):\n",
        "#         noise = torch.randn_like(inputs_embeds, device=inputs_embeds.device) * sigma\n",
        "#         noisy_embeds = inputs_embeds + noise\n",
        "#         try:\n",
        "#             out_noisy = model(inputs_embeds=noisy_embeds, attention_mask=attention_mask)\n",
        "#             logits_noisy = out_noisy.logits if hasattr(out_noisy, 'logits') else out_noisy\n",
        "#         except Exception:\n",
        "#             return _default_smoothing_penalty(logits, lam=lam)\n",
        "#         noisy_logits.append(logits_noisy)\n",
        "\n",
        "#     noisy_stack = torch.stack(noisy_logits, dim=0)\n",
        "#     noisy_mean = noisy_stack.mean(dim=0)\n",
        "\n",
        "#     logp_clean = F.log_softmax(logits / temp, dim=-1)\n",
        "#     p_noisy = F.softmax(noisy_mean / temp, dim=-1)\n",
        "#     kl_per_batch = F.kl_div(logp_clean, p_noisy, reduction='batchmean')\n",
        "#     loss = lam * kl_per_batch\n",
        "#     if reduction == 'mean':\n",
        "#         return loss\n",
        "#     elif reduction == 'sum':\n",
        "#         return loss * logits.shape[0]\n",
        "#     else:\n",
        "#         return loss\n",
        "\n",
        "# def train_model_comprehensive(\n",
        "#     model, model_name, train_loader, val_loader, epochs=max_epochs,\n",
        "#     use_adversarial=False, attack_generator=None, augmentation_ratio=0.65,\n",
        "#     attack_type='mixed', cfg=None, smoothing_penalty_fn=None\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Comprehensive training function with modular structure, improved clarity, and robust error handling.\n",
        "#     Includes gradient accumulation and cosine annealing with warm restarts.\n",
        "#     \"\"\"\n",
        "#     if cfg is None:\n",
        "#         cfg = {}\n",
        "#     if smoothing_penalty_fn is None:\n",
        "#         smoothing_penalty_fn = _default_smoothing_penalty\n",
        "\n",
        "#     effective_use_adv = bool(use_adversarial) and (not cfg.get(\"no_adv\", False))\n",
        "#     apply_smoothing = (not cfg.get(\"no_smooth\", False))\n",
        "\n",
        "#     print(f\"\\n{'='*60}\")\n",
        "#     print(f\"Training {model_name} | cfg={cfg} | use_adversarial(effectively)={effective_use_adv}, smoothing={apply_smoothing}\")\n",
        "#     print(f\"{'='*60}\")\n",
        "\n",
        "#     model = model.to(device)\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=1e-3)\n",
        "\n",
        "#     # === CHECKPOINTING: LOAD STATE IF EXISTS ===\n",
        "#     checkpoint_filename = f\"{model.__class__.__name__}_{model_name}.pth\"\n",
        "#     start_epoch = load_checkpoint(model, optimizer, filename=checkpoint_filename, device=device)\n",
        "#     # === END CHECKPOINTING ===\n",
        "\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#     # Cosine Annealing with Warm Restarts\n",
        "#     scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "#         optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
        "#     )\n",
        "\n",
        "#     early_stopper = EarlyStopper(patience=3, min_delta=0.001)\n",
        "\n",
        "#     history = {\n",
        "#         'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
        "#         'epoch_times': [], 'learning_rates': [], 'resource_usage': []\n",
        "#     }\n",
        "\n",
        "#     best_val_acc = 0\n",
        "#     best_model_state = None\n",
        "\n",
        "#     # Gradient accumulation for effective larger batch size\n",
        "#     accumulation_steps = 2  # effective batch size × 2\n",
        "\n",
        "#     # === CHECKPOINTING: UPDATE LOOP TO START FROM SAVED EPOCH ===\n",
        "#     for epoch in range(start_epoch, epochs):\n",
        "#         epoch_start_time = time.time()\n",
        "#         resource_monitor.start_epoch_monitoring()\n",
        "\n",
        "#         model.train()\n",
        "#         train_loss = 0.0\n",
        "#         train_correct = 0\n",
        "#         train_total = 0\n",
        "\n",
        "#         # Initialize gradients once per epoch\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]', leave=False)\n",
        "#         for batch_idx, batch in enumerate(train_pbar):\n",
        "#             try:\n",
        "#                 input_ids = batch['input_ids'].to(device)\n",
        "#                 attention_mask = batch['attention_mask'].to(device)\n",
        "#                 labels = batch['label'].to(device)\n",
        "\n",
        "#                 if effective_use_adv:\n",
        "#                     loss = trades_loss(model, input_ids, attention_mask, labels, device=device, beta=4.0)\n",
        "#                     with torch.no_grad():\n",
        "#                         outputs = model(input_ids, attention_mask=attention_mask)\n",
        "#                         logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "#                         predictions = torch.argmax(logits, dim=1)\n",
        "#                         correct = (predictions == labels).sum().item()\n",
        "#                         total = len(labels)\n",
        "#                 else:\n",
        "#                     outputs = model(input_ids, attention_mask=attention_mask)\n",
        "#                     logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "#                     ce_loss = criterion(logits, labels)\n",
        "\n",
        "#                     smoothing_loss = 0.0\n",
        "#                     if apply_smoothing and smoothing_penalty_fn is not None:\n",
        "#                         smoothing_loss = smoothing_penalty_fn(\n",
        "#                             model, input_ids, attention_mask, logits,\n",
        "#                             num_samples=3, sigma=0.1, lam=0.05, device=device\n",
        "#                         )\n",
        "\n",
        "#                     loss = ce_loss + smoothing_loss\n",
        "\n",
        "#                     predictions = torch.argmax(logits, dim=1)\n",
        "#                     correct = (predictions == labels).sum().item()\n",
        "#                     total = len(labels)\n",
        "\n",
        "#                 # Gradient accumulation: scale loss\n",
        "#                 loss = loss / accumulation_steps\n",
        "#                 loss.backward()\n",
        "\n",
        "#                 # Only update weights every accumulation_steps batches\n",
        "#                 if (batch_idx + 1) % accumulation_steps == 0:\n",
        "#                     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#                     optimizer.step()\n",
        "#                     optimizer.zero_grad()\n",
        "\n",
        "#                 # Unscale loss for logging\n",
        "#                 train_loss += loss.item() * accumulation_steps\n",
        "#                 train_correct += correct\n",
        "#                 train_total += total\n",
        "\n",
        "#                 current_acc = 100. * train_correct / train_total if train_total > 0 else 0.0\n",
        "#                 train_pbar.set_postfix({\n",
        "#                     'Loss': f'{train_loss/(batch_idx+1):.4f}',\n",
        "#                     'Acc': f'{current_acc:.2f}%'\n",
        "#                 })\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error in training batch {batch_idx}: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#         # Handle any remaining accumulated gradients at epoch end\n",
        "#         if (batch_idx + 1) % accumulation_steps != 0:\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             optimizer.step()\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#         # ---------- validation pass ---------------------\n",
        "#         model.eval()\n",
        "#         val_loss = 0.0\n",
        "#         val_correct = 0\n",
        "#         val_total = 0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]', leave=False)\n",
        "#             for batch_idx, batch in enumerate(val_pbar):\n",
        "#                 try:\n",
        "#                     input_ids = batch['input_ids'].to(device)\n",
        "#                     attention_mask = batch['attention_mask'].to(device)\n",
        "#                     labels = batch['label'].to(device)\n",
        "\n",
        "#                     outputs = model(input_ids, attention_mask=attention_mask)\n",
        "#                     logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "#                     loss = criterion(logits, labels)\n",
        "#                     predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "#                     val_loss += loss.item()\n",
        "#                     val_correct += (predictions == labels).sum().item()\n",
        "#                     val_total += len(labels)\n",
        "\n",
        "#                     current_acc = 100. * val_correct / val_total if val_total > 0 else 0.0\n",
        "#                     val_pbar.set_postfix({\n",
        "#                         'Loss': f'{val_loss/(batch_idx+1):.4f}',\n",
        "#                         'Acc': f'{current_acc:.2f}%'\n",
        "#                     })\n",
        "\n",
        "#                 except Exception as e:\n",
        "#                     print(f\"Error in validation batch {batch_idx}: {e}\")\n",
        "#                     continue\n",
        "\n",
        "#         epoch_resources = resource_monitor.end_epoch_monitoring()\n",
        "#         epoch_time = time.time() - epoch_start_time\n",
        "#         train_loss_avg = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
        "#         train_acc = train_correct / train_total if train_total > 0 else 0.0\n",
        "#         val_loss_avg = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
        "#         val_acc = val_correct / val_total if val_total > 0 else 0.0\n",
        "#         current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "#         history['train_loss'].append(train_loss_avg)\n",
        "#         history['train_acc'].append(train_acc)\n",
        "#         history['val_loss'].append(val_loss_avg)\n",
        "#         history['val_acc'].append(val_acc)\n",
        "#         history['epoch_times'].append(epoch_time)\n",
        "#         history['learning_rates'].append(current_lr)\n",
        "#         history['resource_usage'].append(epoch_resources)\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "#         print(f\"  Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
        "#         print(f\"  Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc*100:.2f}%\")\n",
        "#         print(f\"  Time: {epoch_time:.2f}s, LR: {current_lr:.2e}\")\n",
        "#         print(f\"  GPU Memory: {epoch_resources.get('gpu_memory_mb', 0):.1f}MB\")\n",
        "\n",
        "#         if val_acc > best_val_acc:\n",
        "#             best_val_acc = val_acc\n",
        "#             best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "#             print(f\"  ✓ New best validation accuracy: {val_acc*100:.2f}%\")\n",
        "\n",
        "#         # === CHECKPOINTING: SAVE STATE AFTER EACH EPOCH ===\n",
        "#         save_checkpoint(model, optimizer, epoch, val_loss_avg, filename=checkpoint_filename)\n",
        "#         # === END CHECKPOINTING ===\n",
        "\n",
        "#         # Step scheduler (no argument needed for CosineAnnealingWarmRestarts)\n",
        "#         scheduler.step()\n",
        "\n",
        "#         if early_stopper.early_stop(val_loss_avg):\n",
        "#             print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "#             break\n",
        "\n",
        "#         if epoch % 2 == 0:\n",
        "#             torch.cuda.empty_cache()\n",
        "#             gc.collect()\n",
        "\n",
        "#     if best_model_state is not None:\n",
        "#         model.load_state_dict(best_model_state)\n",
        "#         model.to(device)\n",
        "#         print(f\"\\nLoaded best model with validation accuracy: {best_val_acc*100:.2f}%\")\n",
        "\n",
        "#     history['best_val_acc'] = best_val_acc\n",
        "#     history['total_epochs'] = len(history['train_loss'])\n",
        "\n",
        "#     torch.cuda.empty_cache()\n",
        "#     gc.collect()\n",
        "\n",
        "#     return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1DzVtdBMtZv"
      },
      "source": [
        "# Testing the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyyo94T6MsH0"
      },
      "outputs": [],
      "source": [
        "# # ====\n",
        "# # Train Baseline Model (No Defenses)\n",
        "# # ====\n",
        "\n",
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"TRAINING BASELINE MODEL (Vanilla DistilBERT)\")\n",
        "# print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# # Create model\n",
        "# model_baseline = VanillaDistilBERT(num_classes=2).to(device)\n",
        "\n",
        "# print(f\"Model parameters: {model_baseline.count_parameters():,}\")\n",
        "# print(f\"Model size: {model_baseline.get_model_size():.2f} MB\\n\")\n",
        "\n",
        "# # Training configuration\n",
        "# config_baseline = {\n",
        "#     \"no_adv\": True,      # No adversarial training\n",
        "#     \"no_smooth\": True,   # No smoothing\n",
        "#     \"tag\": \"baseline\"\n",
        "# }\n",
        "\n",
        "# # Train the model\n",
        "# model_baseline, history_baseline = train_model_comprehensive(\n",
        "#     model=model_baseline,\n",
        "#     model_name=\"Vanilla_DistilBERT\",\n",
        "#     train_loader=train_loader,\n",
        "#     val_loader=val_loader,\n",
        "#     epochs=5,  # Start with 5 epochs\n",
        "#     use_adversarial=False,\n",
        "#     cfg=config_baseline\n",
        "# )\n",
        "\n",
        "# # Print results\n",
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"BASELINE TRAINING COMPLETE\")\n",
        "# print(\"=\"*80)\n",
        "# print(f\"Best Validation Accuracy: {history_baseline['best_val_acc']*100:.2f}%\")\n",
        "# print(f\"Final Training Loss: {history_baseline['train_losses'][-1]:.4f}\")\n",
        "# print(f\"Final Validation Loss: {history_baseline['val_losses'][-1]:.4f}\")\n",
        "# print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3715a09b"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import datetime\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Assuming RESULTS_DIR and PLOTS_DIR are defined globally (from akDV7zGLUyBW)\n",
        "# # and max_epochs is defined globally (from Zy1z7OZ8Ka9g)\n",
        "\n",
        "# def now_tag():\n",
        "#     return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# def save_plot(fig, plot_name, prefix=\"experiment\"):\n",
        "#     timestamp = now_tag()\n",
        "#     filename = f\"{prefix}_{plot_name}_{timestamp}.png\"\n",
        "#     # Ensure RESULTS_DIR and PLOTS_DIR are accessible, assuming they are defined in a previous cell\n",
        "#     # or setting them here for independence if needed.\n",
        "#     # For this fix, we assume they are already global.\n",
        "#     global PLOTS_DIR # Access the global variable\n",
        "#     if not 'PLOTS_DIR' in globals():\n",
        "#         # Fallback if PLOTS_DIR is not defined globally (e.g., in a fresh session)\n",
        "#         PLOTS_DIR = Path('plots')\n",
        "#         PLOTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "#     filepath = PLOTS_DIR / filename\n",
        "#     try:\n",
        "#         fig.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "#         print(f\"✅ Plot saved to: {filepath}\")\n",
        "#         return str(filepath)\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Error saving plot: {e}\")\n",
        "#         return None\n",
        "\n",
        "# def plot_individual_model_curves(model_name, data, save_individual=True):\n",
        "#     \"\"\"Plot training curves for a single model\"\"\"\n",
        "#     epochs = range(1, data['epochs'] + 1)\n",
        "\n",
        "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "#     # Plot Loss curves\n",
        "#     ax1.plot(epochs, data['train_losses'], 'b-', label='Training Loss',\n",
        "#              linewidth=2.5, marker='o', markersize=6)\n",
        "#     ax1.plot(epochs, data['val_losses'], 'r-', label='Validation Loss',\n",
        "#              linewidth=2.5, marker='s', markersize=6)\n",
        "#     ax1.set_title(f'{model_name} - Training & Validation Loss',\n",
        "#                   fontsize=14, fontweight='bold')\n",
        "#     ax1.set_xlabel('Epoch', fontsize=12)\n",
        "#     ax1.set_ylabel('Loss', fontsize=12)\n",
        "#     ax1.legend(fontsize=11)\n",
        "#     ax1.grid(True, alpha=0.3)\n",
        "#     ax1.set_xlim(1, data['epochs'])\n",
        "\n",
        "#     # Plot Accuracy curves\n",
        "#     ax2.plot(epochs, data['train_accs'], 'b-', label='Training Accuracy',\n",
        "#              linewidth=2.5, marker='o', markersize=6)\n",
        "#     ax2.plot(epochs, data['val_accs'], 'r-', label='Validation Accuracy',\n",
        "#              linewidth=2.5, marker='s', markersize=6)\n",
        "#     ax2.set_title(f'{model_name} - Training & Validation Accuracy',\n",
        "#                   fontsize=14, fontweight='bold')\n",
        "#     ax2.set_xlabel('Epoch', fontsize=12)\n",
        "#     ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "#     ax2.legend(fontsize=11)\n",
        "#     ax2.grid(True, alpha=0.3)\n",
        "#     ax2.set_xlim(1, data['epochs'])\n",
        "#     ax2.set_ylim(0.75, 1.0)  # Focus on the relevant accuracy range\n",
        "\n",
        "#     plt.tight_layout()\n",
        "\n",
        "#     if save_individual:\n",
        "#         filename = f\"{model_name.replace(' ', '_').replace('(', '').replace(')', '')}_training_curves.png\"\n",
        "#         save_plot(fig, filename) # Use the now local save_plot\n",
        "#         print(f\"Individual plot saved: {filename}\")\n",
        "\n",
        "#     plt.show()\n",
        "\n",
        "# def plot_training_history(history, run_id, save_individual=True):\n",
        "#     \"\"\"\n",
        "#     Map your `history` produced by train_model_comprehensive into\n",
        "#     the schema expected by plot_individual_model_curves and display/save it.\n",
        "#     \"\"\"\n",
        "#     # history keys used earlier: 'train_loss','train_acc','val_loss','val_acc','total_epochs'\n",
        "#     # global max_epochs # Assuming max_epochs is globally defined. If not, pass it as argument.\n",
        "\n",
        "#     epochs = history.get('total_epochs', len(history.get('train_loss', [])))\n",
        "#     data = {\n",
        "#         'epochs': epochs,\n",
        "#         'train_losses': history.get('train_loss', [])[:epochs],\n",
        "#         'val_losses': history.get('val_loss', [])[:epochs],\n",
        "#         'train_accs': history.get('train_acc', [])[:epochs],\n",
        "#         'val_accs': history.get('val_acc', [])[:epochs]\n",
        "#     }\n",
        "#     # Use run_id as model name in filename/title\n",
        "#     plot_individual_model_curves(run_id, data, save_individual=save_individual)\n",
        "\n",
        "# # Check if history_baseline exists and is valid before plotting\n",
        "# if 'history_baseline' in globals() and history_baseline and isinstance(history_baseline, dict) and history_baseline.get('train_loss'):\n",
        "#     print(f\"Plotting training history for {run_id_for_plot}...\")\n",
        "#     plot_training_history(history_baseline, run_id_for_plot)\n",
        "# else:\n",
        "#     print(\"history_baseline is either empty, not a dictionary, or does not contain 'train_loss' data.\")\n",
        "#     print(\"Please ensure a training run has successfully completed and populated 'history_baseline'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.064904Z",
          "iopub.status.busy": "2025-08-12T22:54:05.064715Z",
          "iopub.status.idle": "2025-08-12T22:54:05.080179Z",
          "shell.execute_reply": "2025-08-12T22:54:05.079627Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.064888Z"
        },
        "id": "CAdtPVAHLYX_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Add near the class definition (module/global scope)\n",
        "# def augment_batch_with_adversarial_examples(batch, attack_generator, augmentation_ratio=0.65, attack_type='mixed'):\n",
        "#     # Backwards-compatible wrapper: delegate to the instance method\n",
        "#     return attack_generator.augment_batch_with_adversarial_examples(\n",
        "#         batch, augmentation_ratio=augmentation_ratio, attack_type=attack_type\n",
        "#    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.081466Z",
          "iopub.status.busy": "2025-08-12T22:54:05.0812Z",
          "iopub.status.idle": "2025-08-12T22:54:05.097867Z",
          "shell.execute_reply": "2025-08-12T22:54:05.097301Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.081448Z"
        },
        "id": "dE6D2usoLYX_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def collect_predictions_on_loader(model, loader, device=device):\n",
        "    model.eval()\n",
        "    y_list, p_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            y_list.append(labels.cpu().numpy())\n",
        "            p_list.append(preds)\n",
        "    y_arr = np.concatenate(y_list, axis=0)\n",
        "    p_arr = np.concatenate(p_list, axis=0)\n",
        "    return y_arr, p_arr\n",
        "\n",
        "def collect_adversarial_predictions(model, loader, attack_generator, attack_type='pgd', device=device):\n",
        "    \"\"\"\n",
        "    Given an attack_generator function (same interface as used in training),\n",
        "    create full adversarial batches (augmentation_ratio=1.0) and return preds.\n",
        "    If you have a different eval attack function (e.g., eval_attack), you can\n",
        "    replace this call with yours.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_list, p_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Use your augment_batch_with_adversarial_examples but force augmentation_ratio=1.0\n",
        "            if attack_generator is None:\n",
        "                # fallback to clean if no attack generator provided\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            else:\n",
        "                input_ids_adv, attention_mask_adv, labels_adv = attack_generator.augment_batch_with_adversarial_examples(\n",
        "                            {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels},\n",
        "                    augmentation_ratio=1.0,\n",
        "                    attack_type=attack_type\n",
        "                )\n",
        "                input_ids_adv = input_ids_adv.to(device)\n",
        "                attention_mask_adv = attention_mask_adv.to(device)\n",
        "                outputs = model(input_ids_adv, attention_mask=attention_mask_adv)\n",
        "\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            y_list.append(labels.cpu().numpy())\n",
        "            p_list.append(preds)\n",
        "    y_arr = np.concatenate(y_list, axis=0)\n",
        "    p_arr = np.concatenate(p_list, axis=0)\n",
        "    return y_arr, p_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.098812Z",
          "iopub.status.busy": "2025-08-12T22:54:05.098575Z",
          "iopub.status.idle": "2025-08-12T22:54:05.116776Z",
          "shell.execute_reply": "2025-08-12T22:54:05.116062Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.098795Z"
        },
        "id": "77IL89KgKa9u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# Evaluation and Robustness Testing\n",
        "# ====\n",
        "\n",
        "def evaluate_model_robustness(model, val_loader, attack_generator, model_name):\n",
        "    print(f\"\\nEvaluating {model_name} Robustness...\")\n",
        "\n",
        "    model.eval()\n",
        "    attack_types = ['clean', 'synonym', 'character', 'insertion', 'mixed']\n",
        "    results = {}\n",
        "\n",
        "    # Collect all validation data for evaluation\n",
        "    all_texts = []\n",
        "    all_labels = []\n",
        "    for batch in val_loader:\n",
        "        all_texts.extend([tokenizer.decode(ids, skip_special_tokens=True) for ids in batch['input_ids']])\n",
        "        all_labels.extend(batch['label'].tolist())\n",
        "\n",
        "    all_texts = np.array(all_texts)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    for attack_type in attack_types:\n",
        "        print(f\"Testing {attack_type} attack...\")\n",
        "        predictions = []\n",
        "        latencies = []\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        batch_size_eval = val_loader.batch_size\n",
        "        for i in range(0, len(all_texts), batch_size_eval):\n",
        "            batch_texts = all_texts[i:i+batch_size_eval]\n",
        "            batch_labels = all_labels[i:i+batch_size_eval]\n",
        "\n",
        "            if attack_type == 'clean':\n",
        "                enc = tokenizer(batch_texts.tolist(), return_tensors='pt', padding='max_length', truncation=True, max_length=max_length)\n",
        "                input_ids = enc['input_ids'].to(device)\n",
        "                attention_mask = enc['attention_mask'].to(device)\n",
        "            else:\n",
        "                # Generate adversarial examples\n",
        "                enc_clean = tokenizer(batch_texts.tolist(), return_tensors='pt', padding='max_length', truncation=True, max_length=max_length)\n",
        "                input_ids_clean = enc_clean['input_ids'].to(device)\n",
        "                attention_mask_clean = enc_clean['attention_mask'].to(device)\n",
        "                labels_tensor = torch.tensor(batch_labels).to(device)\n",
        "\n",
        "                input_ids, attention_mask = attack_generator.generate_adversarial_examples(\n",
        "                    input_ids_clean, labels_tensor, model, num_examples=len(batch_labels), attack_type=attack_type, reference_len=max_length\n",
        "                )\n",
        "\n",
        "            start_time = time.time()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
        "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            end_time = time.time()\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            correct += (preds == batch_labels).sum()\n",
        "            total += len(batch_labels)\n",
        "            latencies.append(end_time - start_time)\n",
        "\n",
        "        accuracy = correct / total if total > 0 else 0\n",
        "        f1 = f1_score(all_labels, predictions, average='weighted')\n",
        "\n",
        "        results[attack_type] = {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'latency_avg': np.mean(latencies),\n",
        "            'latency_total': np.sum(latencies),\n",
        "            'predictions': predictions,\n",
        "            'labels': all_labels.tolist()\n",
        "        }\n",
        "        print(f\"{attack_type.capitalize()} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Avg Latency: {np.mean(latencies):.4f}s\")\n",
        "\n",
        "    # Calculate robustness metrics\n",
        "    clean_acc = results['clean']['accuracy']\n",
        "    robustness_scores = {}\n",
        "    for attack_type in ['synonym', 'character', 'insertion', 'mixed']:\n",
        "        attack_acc = results[attack_type]['accuracy']\n",
        "        robustness_drop = clean_acc - attack_acc\n",
        "        robustness_scores[f'{attack_type}_drop'] = robustness_drop\n",
        "        robustness_scores[f'{attack_type}_retention'] = attack_acc / clean_acc if clean_acc > 0 else 0\n",
        "\n",
        "    avg_robustness = np.mean([results[att]['accuracy'] for att in ['synonym', 'character', 'insertion', 'mixed']])\n",
        "    robustness_scores['overall_robustness'] = avg_robustness\n",
        "    robustness_scores['robustness_drop'] = clean_acc - avg_robustness\n",
        "\n",
        "    results['robustness_metrics'] = robustness_scores\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.11837Z",
          "iopub.status.busy": "2025-08-12T22:54:05.117717Z",
          "iopub.status.idle": "2025-08-12T22:54:05.177633Z",
          "shell.execute_reply": "2025-08-12T22:54:05.176909Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.118351Z"
        },
        "id": "uTubIEf8Ka9w",
        "outputId": "1a0406a6-f446-4acd-9261-53049a367e74",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# Utility Functions for Saving and Plotting\n",
        "# ====\n",
        "\n",
        "def save_results(results_dict, filename_prefix=\"experiment\"):\n",
        "    timestamp = now_tag()\n",
        "    filename = f\"{filename_prefix}_{timestamp}.json\"\n",
        "    filepath = RESULTS_DIR / filename\n",
        "\n",
        "    def convert_numpy(obj):\n",
        "        if hasattr(obj, 'tolist'):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, dict):\n",
        "            return {k: convert_numpy(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [convert_numpy(item) for item in obj]\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    serializable_results = convert_numpy(results_dict)\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(serializable_results, f, indent=2, default=str)\n",
        "        print(f\"✅ Results saved to: {filepath}\")\n",
        "        return str(filepath)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving results: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_plot(fig, plot_name, prefix=\"experiment\"):\n",
        "    timestamp = now_tag()\n",
        "    filename = f\"{prefix}_{plot_name}_{timestamp}.png\"\n",
        "    filepath = PLOTS_DIR / filename\n",
        "    try:\n",
        "        fig.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        print(f\"✅ Plot saved to: {filepath}\")\n",
        "        return str(filepath)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error saving plot: {e}\")\n",
        "        return None\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    train_losses = history.get('train_loss', [])\n",
        "    val_losses = history.get('val_loss', [])\n",
        "    train_accs = history.get('train_acc', [])\n",
        "    val_accs = history.get('val_acc', [])\n",
        "\n",
        "    epochs = range(1, max(1, len(train_losses)) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss\n",
        "    ax[0].plot(epochs, train_losses, label='Train Loss', marker='o')\n",
        "    ax[0].plot(epochs, val_losses, label='Val Loss', marker='s')\n",
        "    ax[0].set_title(f'{model_name} Loss')\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].legend()\n",
        "    ax[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy: detect scale (0-1 vs 0-100) and set sensible y-limits\n",
        "    all_accs = list(train_accs) + list(val_accs)\n",
        "    if len(all_accs) == 0:\n",
        "        print(\"No accuracy history to plot.\")\n",
        "        return\n",
        "\n",
        "    max_acc = max(all_accs)\n",
        "    min_acc = min(all_accs)\n",
        "    # If accuracies look like percentages (>1.5), treat as 0-100\n",
        "    if max_acc > 1.5:\n",
        "        ylabel = 'Accuracy (%)'\n",
        "        pad = max(1.0, (max_acc - min_acc) * 0.1)\n",
        "        ymin, ymax = max(0, min_acc - pad), min(100, max_acc + pad)\n",
        "    else:\n",
        "        ylabel = 'Accuracy'\n",
        "        pad = max(0.01, (max_acc - min_acc) * 0.1)\n",
        "        ymin, ymax = max(0.0, min_acc - pad), min(1.0, max_acc + pad)\n",
        "\n",
        "    ax[1].plot(epochs, train_accs, label='Train Accuracy', marker='o')\n",
        "    ax[1].plot(epochs, val_accs, label='Val Accuracy', marker='s')\n",
        "    ax[1].set_title(f'{model_name} Accuracy')\n",
        "    ax[1].set_xlabel('Epoch')\n",
        "    ax[1].set_ylabel(ylabel)\n",
        "    ax[1].legend()\n",
        "    ax[1].grid(True, alpha=0.3)\n",
        "    ax[1].set_ylim(ymin, ymax)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_plot(fig, f\"{model_name}_training_history\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ====\n",
        "# Additional Plots and Statistical Tests\n",
        "# ====\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "def perform_mcnemar_test(preds1, preds2, labels):\n",
        "    correct1 = (preds1 == labels)\n",
        "    correct2 = (preds2 == labels)\n",
        "    n01 = np.sum((correct1 == 1) & (correct2 == 0))\n",
        "    n10 = np.sum((correct1 == 0) & (correct2 == 1))\n",
        "    if n01 + n10 == 0:\n",
        "        return 1.0\n",
        "    mcnemar_stat = (abs(n01 - n10) - 1)**2 / (n01 + n10)\n",
        "    return 1 - stats.chi2.cdf(mcnemar_stat, 1)\n",
        "\n",
        "# Calculate average robust accuracy and robustness drop\n",
        "    avg_robust_acc = [(s+c+i+m)/4 for s,c,i,m in zip(synonym_acc, character_acc, insertion_acc, mixed_acc)]\n",
        "    robustness_drop = [clean - avg for clean, avg in zip(clean_acc, avg_robust_acc)]\n",
        "\n",
        "    return {\n",
        "        'models': models,\n",
        "        'clean_acc': clean_acc,\n",
        "        'synonym_acc': synonym_acc,\n",
        "        'character_acc': character_acc,\n",
        "        'insertion_acc': insertion_acc,\n",
        "        'mixed_acc': mixed_acc,\n",
        "        'avg_robust_acc': avg_robust_acc,\n",
        "        'robustness_drop': robustness_drop,\n",
        "        'trainable_params': trainable_params,\n",
        "        'total_params': total_params\n",
        "    }\n",
        "\n",
        "from matplotlib.patches import Patch\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "# ---- Provided plotting functions (unchanged, copied from your code) ----\n",
        "\n",
        "def plot_individual_performance(data, save_path='individual_performance_clean.png'):\n",
        "    \"\"\"Plot individual model performance across different attack types\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "    attack_types = ['Clean', 'Synonym', 'Character', 'Insertion', 'Mixed']\n",
        "    x = np.arange(len(data['models']))\n",
        "    width = 0.15\n",
        "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
        "\n",
        "    for i, (attack, color) in enumerate(zip(attack_types, colors)):\n",
        "        if attack == 'Clean':\n",
        "            values = data['clean_acc']\n",
        "        elif attack == 'Synonym':\n",
        "            values = data['synonym_acc']\n",
        "        elif attack == 'Character':\n",
        "            values = data['character_acc']\n",
        "        elif attack == 'Insertion':\n",
        "            values = data['insertion_acc']\n",
        "        else:  # Mixed\n",
        "            values = data['mixed_acc']\n",
        "\n",
        "        bars = ax.bar(x + i*width, values, width, label=attack, color=color, alpha=0.8)\n",
        "\n",
        "        for bar, val in zip(bars, values):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                   f'{val:.3f}', ha='center', va='bottom', fontsize=8, rotation=0)\n",
        "\n",
        "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Model Performance Across Different Attack Types', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x + width * 2)\n",
        "    ax.set_xticklabels([m.replace('_', '\\n') for m in data['models']], rotation=45, ha='right')\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.set_ylim(0.7, 1.0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_clean_vs_robust(data, save_path='clean_vs_robust_accuracy.png'):\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    x = np.arange(len(data['models']))\n",
        "    width = 0.35\n",
        "\n",
        "    hatch_clean = '//'\n",
        "    hatch_robust = '\\\\\\\\'\n",
        "\n",
        "    bars1 = ax.bar(x - width/2, data['clean_acc'], width, label='Clean Accuracy',\n",
        "                   color='#3498db', alpha=0.8, edgecolor='black', linewidth=0.5, hatch=hatch_clean)\n",
        "    bars2 = ax.bar(x + width/2, data['avg_robust_acc'], width, label='Average Robust Accuracy',\n",
        "                   color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=0.5, hatch=hatch_robust)\n",
        "\n",
        "    for bar, val in zip(bars1, data['clean_acc']):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "               f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    for bar, val in zip(bars2, data['avg_robust_acc']):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "               f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Clean vs. Average Robust Accuracy Comparison', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels([m.replace('_', '\\n') for m in data['models']], rotation=45, ha='right')\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.set_ylim(0.75, 0.95)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_robustness_drop(data, save_path='robustness_drop_analysis.png'):\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    colors = []\n",
        "    hatches = []\n",
        "    for model in data['models']:\n",
        "        if 'Enhanced_HAT-D' in model:\n",
        "            colors.append('#f39c12')  # Orange for our method\n",
        "            hatches.append('//')\n",
        "        elif 'Adversarial_Training' in model:\n",
        "            colors.append('#2ecc71')  # Green for best performing\n",
        "            hatches.append('\\\\\\\\')\n",
        "        elif 'Ensemble_Defense' in model:\n",
        "            colors.append('#e74c3c')  # Red for ensemble\n",
        "            hatches.append('xx')\n",
        "        else:\n",
        "            colors.append('#3498db')  # Blue for baseline methods\n",
        "            hatches.append('..')\n",
        "\n",
        "    bars = ax.bar(range(len(data['models'])), data['robustness_drop'], color=colors, alpha=0.8,\n",
        "                  edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    for bar, hatch in zip(bars, hatches):\n",
        "        bar.set_hatch(hatch)\n",
        "\n",
        "    for bar, val in zip(bars, data['robustness_drop']):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
        "               f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Robustness Drop (Clean Acc. - Avg Robust Acc.)', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Model Robustness Drop Analysis', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(range(len(data['models'])))\n",
        "    ax.set_xticklabels([m.replace('_', '\\n') for m in data['models']], rotation=45, ha='right')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    ax.set_ylim(0, max(data['robustness_drop']) * 1.15)\n",
        "\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='#3498db', label='Baseline Methods', hatch='..'),\n",
        "        Patch(facecolor='#2ecc71', label='Best Performing', hatch='\\\\\\\\'),\n",
        "        Patch(facecolor='#f39c12', label='Our Method', hatch='//'),\n",
        "        Patch(facecolor='#e74c3c', label='High Parameter Count', hatch='xx')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_efficiency_analysis(data, save_path='model_efficiency_analysis.png'):\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    trainable_params_millions = [p/1e6 for p in data['trainable_params']]\n",
        "\n",
        "    colors = []\n",
        "    hatches = []\n",
        "    for model in data['models']:\n",
        "        if 'Enhanced_HAT-D' in model:\n",
        "            colors.append('#f39c12')  # Orange for our method\n",
        "            hatches.append('//')\n",
        "        elif 'Ensemble_Defense' in model:\n",
        "            colors.append('#e74c3c')  # Red for high parameter count\n",
        "            hatches.append('xx')\n",
        "        else:\n",
        "            colors.append('#3498db')  # Blue for others\n",
        "            hatches.append('..')\n",
        "\n",
        "    bars = ax.barh(range(len(data['models'])), trainable_params_millions, color=colors,\n",
        "                   alpha=0.8, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "    for bar, hatch in zip(bars, hatches):\n",
        "        bar.set_hatch(hatch)\n",
        "\n",
        "    for i, (bar, val) in enumerate(zip(bars, trainable_params_millions)):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width + 2, bar.get_y() + bar.get_height()/2.,\n",
        "               f'{val:.1f}M', ha='left', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "    ax.set_ylabel('Models', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Trainable Parameters (Millions)', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Model Efficiency Analysis (Trainable Parameters)', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.set_yticks(range(len(data['models'])))\n",
        "    ax.set_yticklabels([m.replace('_', ' ') for m in data['models']])\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "    ax.set_xlim(0, max(trainable_params_millions) * 1.15)\n",
        "\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='#3498db', label='Standard Models', hatch='..'),\n",
        "        Patch(facecolor='#f39c12', label='Our Method (Efficient)', hatch='//'),\n",
        "        Patch(facecolor='#e74c3c', label='High Parameter Count', hatch='xx')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_tradeoff_analysis(data, save_path='robustness_vs_accuracy_tradeoff.png'):\n",
        "    \"\"\"Plot robustness vs accuracy trade-off\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    colors = []\n",
        "    sizes = []\n",
        "    markers = []\n",
        "    for i, model in enumerate(data['models']):\n",
        "        if 'Enhanced_HAT-D' in model:\n",
        "            colors.append('#f39c12')\n",
        "            sizes.append(120)\n",
        "            markers.append('o')  # Circle\n",
        "        elif 'Adversarial_Training' in model:\n",
        "            colors.append('#2ecc71')\n",
        "            sizes.append(100)\n",
        "            markers.append('s')  # Square\n",
        "        elif 'Ensemble_Defense' in model:\n",
        "            colors.append('#e74c3c')\n",
        "            sizes.append(100)\n",
        "            markers.append('^')  # Triangle\n",
        "        else:\n",
        "            colors.append('#3498db')\n",
        "            sizes.append(80)\n",
        "            markers.append('D')  # Diamond\n",
        "\n",
        "    for i, (x_val, y_val) in enumerate(zip(data['clean_acc'], data['avg_robust_acc'])):\n",
        "        ax.scatter(x_val, y_val, c=colors[i], s=sizes[i], marker=markers[i],\n",
        "                   edgecolors='black', linewidth=1, alpha=0.7)\n",
        "\n",
        "    min_acc = min(min(data['clean_acc']), min(data['avg_robust_acc'])) - 0.02\n",
        "    max_acc = max(max(data['clean_acc']), max(data['avg_robust_acc'])) + 0.01\n",
        "    ax.set_xlim(min_acc, max_acc)\n",
        "    ax.set_ylim(min_acc, max_acc)\n",
        "    ax.plot([min_acc, max_acc], [min_acc, max_acc], 'k--', alpha=0.5, linewidth=1, label='Perfect Robustness Line')\n",
        "\n",
        "    ax.set_xlabel('Clean Accuracy', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Average Robust Accuracy', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Robustness vs. Accuracy Trade-off', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Legend with marker shapes\n",
        "    legend_elements = [\n",
        "        Line2D([0], [0], marker='o', color='w', label='Enhanced HAT-D (Ours)',\n",
        "               markerfacecolor='#f39c12', markersize=10, markeredgecolor='black'),\n",
        "        Line2D([0], [0], marker='s', color='w', label='Adversarial Training',\n",
        "               markerfacecolor='#2ecc71', markersize=8, markeredgecolor='black'),\n",
        "        Line2D([0], [0], marker='^', color='w', label='Ensemble Defense',\n",
        "               markerfacecolor='#e74c3c', markersize=8, markeredgecolor='black'),\n",
        "        Line2D([0], [0], marker='D', color='w', label='Baseline Methods',\n",
        "               markerfacecolor='#3498db', markersize=6, markeredgecolor='black'),\n",
        "        Line2D([0], [0], linestyle='--', color='k', label='Perfect Robustness Line')\n",
        "    ]\n",
        "\n",
        "    ax.legend(handles=legend_elements, loc='lower right')\n",
        "    ax.set_xlim(0.75, 0.9)\n",
        "    ax.set_ylim(0.75, 0.9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_performance_summary(data, save_path='performance_summary_table.png'):\n",
        "    \"\"\"Create performance summary table\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "\n",
        "    table_data = []\n",
        "    for i, model in enumerate(data['models']):\n",
        "        if model == 'Enhanced_HAT-D (Ours)':\n",
        "            status = 'OURS'\n",
        "        elif model == 'Adversarial_Training':\n",
        "            status = 'BEST'\n",
        "        elif model == 'Ensemble_Defense':\n",
        "            status = 'FIXED'\n",
        "        else:\n",
        "            status = 'OK'\n",
        "\n",
        "        table_data.append([\n",
        "            model.replace('_', ' '),\n",
        "            f\"{data['clean_acc'][i]:.3f}\",\n",
        "            f\"{data['avg_robust_acc'][i]:.3f}\",\n",
        "            f\"{data['robustness_drop'][i]:.3f}\",\n",
        "            status\n",
        "        ])\n",
        "\n",
        "    table = ax.table(cellText=table_data,\n",
        "                    colLabels=['Model', 'Clean Acc.', 'Robust Acc.', 'Robustness Drop', 'Status'],\n",
        "                    cellLoc='center',\n",
        "                    loc='center',\n",
        "                    bbox=[0, 0, 1, 1])\n",
        "\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(1, 2)\n",
        "\n",
        "    for i in range(len(data['models'])):\n",
        "        if table_data[i][4] == 'OURS':\n",
        "            table[(i+1, 4)].set_facecolor('#f39c12')\n",
        "            table[(i+1, 4)].set_text_props(weight='bold', color='white')\n",
        "        elif table_data[i][4] == 'BEST':\n",
        "            table[(i+1, 4)].set_facecolor('#2ecc71')\n",
        "            table[(i+1, 4)].set_text_props(weight='bold', color='white')\n",
        "        elif table_data[i][4] == 'FIXED':\n",
        "            table[(i+1, 4)].set_facecolor('#e74c3c')\n",
        "            table[(i+1, 4)].set_text_props(weight='bold', color='white')\n",
        "        else:\n",
        "            table[(i+1, 4)].set_facecolor('#3498db')\n",
        "            table[(i+1, 4)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    for j in range(5):\n",
        "        table[(0, j)].set_facecolor('#34495e')\n",
        "        table[(0, j)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "    plt.title('Performance Summary', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# ---- Adapter: training-history -> plot_individual_model_curves ----------------\n",
        "\n",
        "def plot_individual_model_curves(model_name, data, save_individual=True):\n",
        "    \"\"\"Plot training curves for a single model\"\"\"\n",
        "    epochs = range(1, data['epochs'] + 1)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Plot Loss curves\n",
        "    ax1.plot(epochs, data['train_losses'], 'b-', label='Training Loss',\n",
        "             linewidth=2.5, marker='o', markersize=6)\n",
        "    ax1.plot(epochs, data['val_losses'], 'r-', label='Validation Loss',\n",
        "             linewidth=2.5, marker='s', markersize=6)\n",
        "    ax1.set_title(f'{model_name} - Training & Validation Loss',\n",
        "                  fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Epoch', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.legend(fontsize=11)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_xlim(1, data['epochs'])\n",
        "\n",
        "    # Plot Accuracy curves\n",
        "    ax2.plot(epochs, data['train_accs'], 'b-', label='Training Accuracy',\n",
        "             linewidth=2.5, marker='o', markersize=6)\n",
        "    ax2.plot(epochs, data['val_accs'], 'r-', label='Validation Accuracy',\n",
        "             linewidth=2.5, marker='s', markersize=6)\n",
        "    ax2.set_title(f'{model_name} - Training & Validation Accuracy',\n",
        "                  fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Epoch', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax2.legend(fontsize=11)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_xlim(1, data['epochs'])\n",
        "    ax2.set_ylim(0.75, 1.0)  # Focus on the relevant accuracy range\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_individual:\n",
        "        filename = f\"{model_name.replace(' ', '_').replace('(', '').replace(')', '')}_training_curves.png\"\n",
        "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Individual plot saved: {filename}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ---- Adapter wrappers used by run_experiment ------------------------------------------------\n",
        "\n",
        "def plot_training_history(history, run_id, save_individual=True):\n",
        "    \"\"\"\n",
        "    Map your `history` produced by train_model_comprehensive into\n",
        "    the schema expected by plot_individual_model_curves and display/save it.\n",
        "    \"\"\"\n",
        "    # history keys used earlier: 'train_loss','train_acc','val_loss','val_acc','total_epochs'\n",
        "    epochs = history.get('total_epochs', len(history.get('train_loss', [])))\n",
        "    data = {\n",
        "        'epochs': epochs,\n",
        "        'train_losses': history.get('train_loss', [])[:epochs],\n",
        "        'val_losses': history.get('val_loss', [])[:epochs],\n",
        "        'train_accs': history.get('train_acc', [])[:epochs],\n",
        "        'val_accs': history.get('val_acc', [])[:epochs]\n",
        "    }\n",
        "    # Use run_id as model name in filename/title\n",
        "    plot_individual_model_curves(run_id, data, save_individual=save_individual)\n",
        "\n",
        "def create_summary_plots(results_df, save_dir=None):\n",
        "    \"\"\"\n",
        "    Build the `data` dict expected by the plotting functions from results_df.\n",
        "    results_df is expected to have at least: model_name, clean_acc, adv_acc (or pgd_acc/fgsm_acc)\n",
        "    If attack-specific columns exist, use them; otherwise fall back to adv_acc.\n",
        "    \"\"\"\n",
        "    if save_dir is None:\n",
        "        save_dir = Path.cwd()\n",
        "\n",
        "    # Convert to DataFrame (if not already)\n",
        "    if not isinstance(results_df, pd.DataFrame):\n",
        "        results_df = pd.DataFrame(results_df)\n",
        "\n",
        "    models = results_df['model_name'].tolist()\n",
        "    clean_acc = results_df['clean_acc'].tolist()\n",
        "\n",
        "    # Attempt to pick individual attack columns if present\n",
        "    synonym_acc = results_df.get('synonym_acc', None)\n",
        "    character_acc = results_df.get('character_acc', None)\n",
        "    insertion_acc = results_df.get('insertion_acc', None)\n",
        "    mixed_acc = results_df.get('mixed_acc', None)\n",
        "\n",
        "    # Fallbacks: use adv/pgd/fgsm columns if specific ones missing\n",
        "    fallback_adv = None\n",
        "    for col in ['avg_robust_acc', 'adv_acc', 'pgd_acc', 'fgsm_acc']:\n",
        "        if col in results_df.columns:\n",
        "            fallback_adv = results_df[col].tolist()\n",
        "            break\n",
        "\n",
        "    # If specific attack lists are missing, copy fallback into all of them\n",
        "    if synonym_acc is None:\n",
        "        synonym_acc = fallback_adv if fallback_adv is not None else clean_acc\n",
        "    if character_acc is None:\n",
        "        character_acc = fallback_adv if fallback_adv is not None else clean_acc\n",
        "    if insertion_acc is None:\n",
        "        insertion_acc = fallback_adv if fallback_adv is not None else clean_acc\n",
        "    if mixed_acc is None:\n",
        "        mixed_acc = fallback_adv if fallback_adv is not None else clean_acc\n",
        "\n",
        "    # ensure lists\n",
        "    synonym_acc = list(synonym_acc)\n",
        "    character_acc = list(character_acc)\n",
        "    insertion_acc = list(insertion_acc)\n",
        "    mixed_acc = list(mixed_acc)\n",
        "\n",
        "    # Compute average robust accuracy if not present\n",
        "    if 'avg_robust_acc' in results_df.columns:\n",
        "        avg_robust_acc = results_df['avg_robust_acc'].tolist()\n",
        "    else:\n",
        "        avg_robust_acc = [(s+c+i+m)/4 for s,c,i,m in zip(synonym_acc, character_acc, insertion_acc, mixed_acc)]\n",
        "\n",
        "    robustness_drop = [clean - avg for clean, avg in zip(clean_acc, avg_robust_acc)]\n",
        "\n",
        "    # For params: try to use columns if available, otherwise set to zeros\n",
        "    trainable_params = results_df.get('num_trainable_params', [0]*len(models)).tolist()\n",
        "    total_params = results_df.get('total_params', [0]*len(models)).tolist()\n",
        "\n",
        "    data = {\n",
        "        'models': models,\n",
        "        'clean_acc': clean_acc,\n",
        "        'synonym_acc': synonym_acc,\n",
        "        'character_acc': character_acc,\n",
        "        'insertion_acc': insertion_acc,\n",
        "        'mixed_acc': mixed_acc,\n",
        "        'avg_robust_acc': avg_robust_acc,\n",
        "        'robustness_drop': robustness_drop,\n",
        "        'trainable_params': trainable_params,\n",
        "        'total_params': total_params\n",
        "    }\n",
        "\n",
        "    # Call the plotting functions you added\n",
        "    plot_individual_performance(data, save_path=str(Path(save_dir) / 'individual_performance_clean.png'))\n",
        "    plot_clean_vs_robust(data, save_path=str(Path(save_dir) / 'clean_vs_robust_accuracy.png'))\n",
        "    plot_robustness_drop(data, save_path=str(Path(save_dir) / 'robustness_drop_analysis.png'))\n",
        "    plot_efficiency_analysis(data, save_path=str(Path(save_dir) / 'model_efficiency_analysis.png'))\n",
        "    plot_tradeoff_analysis(data, save_path=str(Path(save_dir) / 'robustness_vs_accuracy_tradeoff.png'))\n",
        "    plot_performance_summary(data, save_path=str(Path(save_dir) / 'performance_summary_table.png'))\n",
        "\n",
        "def plot_individual_results(results_df, save_dir=None):\n",
        "    \"\"\"\n",
        "    Secondary wrapper (keeps compatibility with earlier calls that used plot_individual_results).\n",
        "    \"\"\"\n",
        "    create_summary_plots(results_df, save_dir=save_dir)\n",
        "\n",
        "print(\"Analysis and visualization functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.178718Z",
          "iopub.status.busy": "2025-08-12T22:54:05.178457Z",
          "iopub.status.idle": "2025-08-12T22:54:05.195301Z",
          "shell.execute_reply": "2025-08-12T22:54:05.194726Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.178689Z"
        },
        "id": "8FM1UshFLYYD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Replace your existing run_experiment cell with this one.\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Ensure these globals exist: RUN_MATRIX, RESULTS_DIR, RESULTS_PATH, build_run_id_from_cfg, log_run\n",
        "# Ensure train_model_comprehensive accepts `cfg` and `smoothing_penalty_fn`\n",
        "# Ensure randomized_smoothing_penalty and collect_predictions_on_loader / collect_adversarial_predictions exist\n",
        "\n",
        "def _compute_run_stats_and_save_preds(run_id, model, val_loader, attack_generator, device=device):\n",
        "    \"\"\"\n",
        "    Compute accuracies and save per-sample predictions for the run.\n",
        "    Returns stats dict (clean_acc, pgd_acc, fgsm_acc) and dict of arrays.\n",
        "    \"\"\"\n",
        "    # Clean preds\n",
        "    y_clean, preds_clean = collect_predictions_on_loader(model, val_loader, device=device)\n",
        "    # Adversarial preds (PGD & FGSM)\n",
        "    y_pgd, preds_pgd = collect_adversarial_predictions(model, val_loader, attack_generator, attack_type='pgd', device=device)\n",
        "    y_fgsm, preds_fgsm = collect_adversarial_predictions(model, val_loader, attack_generator, attack_type='fgsm', device=device)\n",
        "\n",
        "    # Ensure y arrays align; prefer y_clean as canonical ordering\n",
        "    # Compute accuracies (percent)\n",
        "    clean_acc = 100.0 * np.mean(preds_clean == y_clean)\n",
        "    pgd_acc   = 100.0 * np.mean(preds_pgd == y_pgd)\n",
        "    fgsm_acc  = 100.0 * np.mean(preds_fgsm == y_fgsm)\n",
        "\n",
        "    stats = {\n",
        "        \"run_id\": run_id,\n",
        "        \"clean_acc\": float(clean_acc),\n",
        "        \"pgd_acc\": float(pgd_acc),\n",
        "        \"fgsm_acc\": float(fgsm_acc),\n",
        "        \"n_test\": int(len(y_clean))\n",
        "    }\n",
        "\n",
        "    # Save per-sample arrays for statistical tests\n",
        "    np.save(RESULTS_DIR / f\"y_{run_id}.npy\", y_clean)\n",
        "    np.save(RESULTS_DIR / f\"preds_clean_{run_id}.npy\", preds_clean)\n",
        "    np.save(RESULTS_DIR / f\"preds_pgd_{run_id}.npy\", preds_pgd)\n",
        "    np.save(RESULTS_DIR / f\"preds_fgsm_{run_id}.npy\", preds_fgsm)\n",
        "\n",
        "    return stats, {\"y_true\": y_clean, \"preds_clean\": preds_clean, \"preds_pgd\": preds_pgd, \"preds_fgsm\": preds_fgsm}\n",
        "\n",
        "\n",
        "def contingency_table_from_preds(y_true, preds_a, preds_b):\n",
        "    a_corr = (preds_a == y_true)\n",
        "    b_corr = (preds_b == y_true)\n",
        "    n11 = int(np.sum(np.logical_and(a_corr, b_corr)))\n",
        "    n10 = int(np.sum(np.logical_and(a_corr, np.logical_not(b_corr))))\n",
        "    n01 = int(np.sum(np.logical_and(np.logical_not(a_corr), b_corr)))\n",
        "    n00 = int(np.sum(np.logical_and(np.logical_not(a_corr), np.logical_not(b_corr))))\n",
        "    return np.array([[n11, n10], [n01, n00]]), a_corr, b_corr\n",
        "\n",
        "def pairwise_stats(y_true, preds_a, preds_b):\n",
        "    table, _, _ = contingency_table_from_preds(y_true, preds_a, preds_b)\n",
        "    n_total = int(table.sum())\n",
        "    # McNemar\n",
        "    mcnemar_res = mcnemar(table, exact=False)\n",
        "    m_stat = float(mcnemar_res.statistic)\n",
        "    m_p = float(mcnemar_res.pvalue)\n",
        "    # Chi-square test (no Yates correction here)\n",
        "    chi2, chi2_p, dof, expected = chi2_contingency(table, correction=False)\n",
        "    phi = np.sqrt(chi2 / n_total) if n_total > 0 else float('nan')\n",
        "    return {\n",
        "        \"contingency_table\": table.tolist(),\n",
        "        \"mcnemar_stat\": m_stat, \"mcnemar_p\": m_p,\n",
        "        \"chi2\": float(chi2), \"chi2_p\": float(chi2_p), \"chi2_dof\": int(dof),\n",
        "        \"chi2_expected\": expected.tolist(),\n",
        "        \"phi\": float(phi),\n",
        "        \"n\": n_total\n",
        "    }\n",
        "\n",
        "def perform_pairwise_tests_for_model(run_pred_map):\n",
        "    \"\"\"\n",
        "    run_pred_map: dict run_id -> {'y_true':..., 'preds_clean': ...}\n",
        "    Returns dict of pairwise stats for all combinations.\n",
        "    \"\"\"\n",
        "    pairwise_results = {}\n",
        "    run_ids = sorted(run_pred_map.keys())\n",
        "    for a_id, b_id in itertools.combinations(run_ids, 2):\n",
        "        y_true = run_pred_map[a_id]['y_true']\n",
        "        preds_a = run_pred_map[a_id]['preds_clean']\n",
        "        preds_b = run_pred_map[b_id]['preds_clean']\n",
        "        stats = pairwise_stats(y_true, preds_a, preds_b)\n",
        "        pairwise_results[f\"{a_id}__vs__{b_id}\"] = stats\n",
        "    return pairwise_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.196421Z",
          "iopub.status.busy": "2025-08-12T22:54:05.196151Z",
          "iopub.status.idle": "2025-08-12T22:54:05.213904Z",
          "shell.execute_reply": "2025-08-12T22:54:05.213058Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.196399Z"
        },
        "id": "tdyM4hQGLYYF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convert_np_types(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convert_np_types(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_np_types(i) for i in obj]\n",
        "    elif isinstance(obj, (np.integer,)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating,)):\n",
        "        return float(obj)\n",
        "    else:\n",
        "        return obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.215146Z",
          "iopub.status.busy": "2025-08-12T22:54:05.214706Z",
          "iopub.status.idle": "2025-08-12T22:54:05.52487Z",
          "shell.execute_reply": "2025-08-12T22:54:05.524051Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.215119Z"
        },
        "id": "ePmViPrRKa-A",
        "outputId": "13c25255-51e8-4169-d873-d9513321af90",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!ls -lh plots | head\n",
        "!ls -lh results | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "be12176f31444999b0853525afa3df5d",
            "4b760e73afe14d5882f3c40ac44f6985",
            "f20e5dd191fa421db1f7f7f345a43129",
            "d6d0f1d8016746cfa53d5a3209023665",
            "57a2f963c3ec4de4a0965d709f83a000",
            "7d00a0fbaecb4b79977220a078a6b0ba",
            "1f4d7bbffcef46a68c629d1809dd302b",
            "9ee501e9849a49d495a2a1d4f962add4",
            "ebc250e7e4974f94bdb4f9e13ce62aa9",
            "7bc3c25fe5e54e7b8b21c041027a593e",
            "28fbfaca8a35424ebf2866490d64af2c",
            "c6e638c143cf4433bf9d1f67a1ba1ff8",
            "d5190108478844a6a70bfc2a3e33398c",
            "fc97d36e68b84e51b5c64fb7aec8c013",
            "68f4f6ec1b7b4fec96cff5b3ebd9066a",
            "eb89be4713094190bfc5b23a97156abe",
            "60a5fa507ab94e929f4cd8c26945f77f",
            "23baad196aad4b8aac49a1e78b08494f",
            "a3d802c549e04055bc59827759c8d4f2",
            "abbd23acb22b439280cb4c0cfca2726d",
            "c4e57b1714a44d2fb4b04a1dc24201fe",
            "b789f013c08940c3a9d3b19d2456c750",
            "bf75b7c2a23c40dda64763b9e0ddfc6f",
            "7d4b20b7e6b4417ba2cfaad7185eee75",
            "2247b6a06ec3444289e3ffbda446c7d1",
            "49504cae3b2448b4af0b82a14193a5c5",
            "e09fb4098e6e45249884df91728be0b6",
            "efbebc4a89624fba93067959ded6470c",
            "f3573605504b48dcb8333e271ad21893",
            "c8808622d3634d59b6ed8cbb74c502cd",
            "4c162f6a52f24ee7ab7a193ced8431f8",
            "8b7dafe0b58f4a108f1b74113adabe69",
            "138ca9b46c874f8fa9180a94e3d39972",
            "d7d1ee9b2ba84c05a0e55d6f4e5c37c4",
            "b813a9e465534e19ab28c8fc815141f8",
            "5ee54968a4ff4805a467b4fb399c04ce",
            "5f7c98a401514bfb96dd5a30c614d329",
            "8bfab1d4ff494753a63a0749f35d8892",
            "69b8ce6f7ca7446ca4279d59e2243ec0",
            "0ca2abbe590c47ee9807afb8487c7195",
            "1f4563a358d54541a3d81a414240906d",
            "d4d89f8576c443a8aaa2a622b3958cf0",
            "a9524c9aec154071817a5dccf94336b3",
            "38a675053a6841df81aa112da7a5f50d"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-08-12T22:54:05.526756Z",
          "iopub.status.busy": "2025-08-12T22:54:05.52644Z",
          "iopub.status.idle": "2025-08-13T04:13:35.316693Z",
          "shell.execute_reply": "2025-08-13T04:13:35.315718Z",
          "shell.execute_reply.started": "2025-08-12T22:54:05.526724Z"
        },
        "id": "_l0lWflCLYYG",
        "outputId": "f442fd1a-3977-424c-b7e6-152756e40fc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def run_experiment_ablation():\n",
        "    \"\"\"\n",
        "    Runs the 4-run mini-ablation for each model in MODEL_REGISTRY.\n",
        "    Saves per-run predictions to results/ and computes pairwise stats (McNemar + Chi2).\n",
        "    Returns a nested dictionary of results_all_models[model_name][run_id] = stats\n",
        "    \"\"\"\n",
        "    results_all_models = {}\n",
        "\n",
        "    for model_name, model_class in MODEL_REGISTRY.items():\n",
        "        print(f\"\\n--- Starting experiments for {model_name} (ablation matrix) ---\")\n",
        "        model_results = {}         # store per-run summary stats\n",
        "        run_preds_for_stats = {}   # store per-run per-sample preds for statistical tests\n",
        "\n",
        "        for cfg in RUN_MATRIX:\n",
        "            run_id = build_run_id_from_cfg(cfg)\n",
        "            print(f\"\\n>>> Running {run_id} for model {model_name}\")\n",
        "\n",
        "            # instantiate fresh model for each run\n",
        "            model = model_class()\n",
        "            model.to(device)\n",
        "\n",
        "            # attack generator depends on model instance\n",
        "            attack_generator = AdversarialAttackGenerator(model, tokenizer, device)\n",
        "\n",
        "            # Determine original use_adversarial boolean (keep old behaviour but allow cfg override)\n",
        "            use_adv_flag = (model_name == 'Adversarial_Training')\n",
        "\n",
        "            # Train: pass cfg and smoothing_penalty_fn (randomized smoothing)\n",
        "            trained_model, history = train_model_comprehensive(\n",
        "                model, run_id, train_loader, val_loader,\n",
        "                epochs=max_epochs,\n",
        "                use_adversarial=use_adv_flag,\n",
        "                attack_generator=attack_generator,\n",
        "                augmentation_ratio=0.65,\n",
        "                attack_type='mixed',\n",
        "                cfg=cfg,\n",
        "                smoothing_penalty_fn=randomized_smoothing_penalty  # will fallback internally if unsupported\n",
        "            )\n",
        "\n",
        "            # Plot training history (existing util)\n",
        "            try:\n",
        "                plot_training_history(history, run_id)\n",
        "            except Exception:\n",
        "                print(\"plot_training_history failed or not available; continuing.\")\n",
        "\n",
        "            # Evaluate robustness (user utility) — keep for convenience but also collect per-sample preds\n",
        "            try:\n",
        "                robustness_results = evaluate_model_robustness(trained_model, val_loader, attack_generator, run_id)\n",
        "            except Exception:\n",
        "                robustness_results = {}\n",
        "\n",
        "            # Compute & save per-sample stats and arrays\n",
        "            stats, preds_dict = _compute_run_stats_and_save_preds(run_id, trained_model, val_loader, attack_generator, device=device)\n",
        "\n",
        "            # Merge robustness_results into stats if available\n",
        "            stats.update(robustness_results if isinstance(robustness_results, dict) else {})\n",
        "\n",
        "            # Add model meta\n",
        "            stats.update({\n",
        "                'model_size_MB': trained_model.get_model_size() if hasattr(trained_model, 'get_model_size') else None,\n",
        "                'num_trainable_params': trained_model.count_parameters() if hasattr(trained_model, 'count_parameters') else None,\n",
        "                'history': history\n",
        "            })\n",
        "            # === Inside the run_experiment_ablation function, within the `for cfg in RUN_MATRIX:` loop ===\n",
        "\n",
        "            # ... (after stats dictionary is created) ...\n",
        "\n",
        "            # --- REPLACEMENT FOR LOGGING ---\n",
        "            # Remove the old JSON logger: log_run(run_id, stats)\n",
        "\n",
        "            # Create a clean, summarized version of stats for CSV logging\n",
        "            # We exclude the full epoch-by-epoch history to keep the CSV clean\n",
        "            csv_stats = stats.copy()\n",
        "            if 'history' in csv_stats:\n",
        "                # Keep only the summary metrics from history\n",
        "                history_summary = {\n",
        "                    'best_val_acc': csv_stats['history'].get('best_val_acc'),\n",
        "                    'total_epochs': csv_stats['history'].get('total_epochs')\n",
        "                }\n",
        "                csv_stats['history'] = history_summary\n",
        "\n",
        "            # Use the new CSV logger\n",
        "            log_run_csv(run_id, csv_stats)\n",
        "            # --- END OF REPLACEMENT ---\n",
        "\n",
        "            # store in memory (this part is unchanged)\n",
        "            model_results[run_id] = stats\n",
        "            run_preds_for_stats[run_id] = {'y_true': preds_dict['y_true'], 'preds_clean': preds_dict['preds_clean']}\n",
        "            # log to aggregate.json\n",
        "            log_run_csv(run_id, csv_stats)\n",
        "\n",
        "\n",
        "        # After all RUN_MATRIX runs for this model: compute pairwise stats (BASE vs others)\n",
        "        pairwise_results = perform_pairwise_tests_for_model(run_preds_for_stats)\n",
        "\n",
        "        # print succinct BASE comparisons\n",
        "        print(f\"\\nPairwise stats for model {model_name} (showing BASE comparisons):\")\n",
        "        for key, val in pairwise_results.items():\n",
        "            if key.startswith(\"BASE__vs__\") or key.endswith(\"__vs__BASE\"):\n",
        "                print(key)\n",
        "                print(\"  contingency:\", val[\"contingency_table\"])\n",
        "                print(f\"  McNemar: stat={val['mcnemar_stat']:.3f}, p={val['mcnemar_p']:.4f}\")\n",
        "                print(f\"  Chi2:    χ2={val['chi2']:.3f}, p={val['chi2_p']:.4f}, phi={val['phi']:.4f}, n={val['n']}\")\n",
        "                print(\"\")\n",
        "\n",
        "        # # Save pairwise stats into aggregate.json under model name\n",
        "        # # Load aggregate, inject pairwise under a keyed name and save back\n",
        "        # try:\n",
        "        #     aggregate = json.load(open(RESULTS_PATH, \"r\"))\n",
        "        # except Exception:\n",
        "        #     aggregate = {}\n",
        "        # aggregate_key = f\"{model_name}__pairwise_stats\"\n",
        "        # aggregate[aggregate_key] = pairwise_results\n",
        "        # aggregate_clean = convert_np_types(aggregate)  # <-- convert here\n",
        "        # json.dump(aggregate_clean, open(RESULTS_PATH, \"w\"), indent=2)\n",
        "        # print(f\"Saved pairwise stats to {RESULTS_PATH} under key {aggregate_key}\")\n",
        "\n",
        "        results_all_models[model_name] = model_results\n",
        "\n",
        "\n",
        "        # Build a summary DataFrame across models using the BASE run for each model (fall back to first run)\n",
        "        summary_rows = []\n",
        "        for model_name, model_runs in results_all_models.items():\n",
        "            # find the BASE configuration run (cfg with no_adv=False and no_smooth=False)\n",
        "            base_stats = None\n",
        "            for run_id, st in model_runs.items():\n",
        "                cfg = st.get('cfg', {})\n",
        "                if not cfg.get('no_adv', False) and not cfg.get('no_smooth', False):\n",
        "                    base_stats = st\n",
        "                    break\n",
        "            # fallback: if no explicit BASE found, take the first recorded run\n",
        "            if base_stats is None and len(model_runs) > 0:\n",
        "                base_stats = next(iter(model_runs.values()))\n",
        "\n",
        "            if base_stats is None:\n",
        "                # nothing recorded for this model (shouldn't happen) -- skip\n",
        "                continue\n",
        "\n",
        "            # normalize field names (handle possible name variants)\n",
        "            clean_acc = base_stats.get('clean_acc') or base_stats.get('clean_accuracy') or base_stats.get('clean')\n",
        "            pgd_acc = base_stats.get('pgd_acc') or base_stats.get('adv_acc') or base_stats.get('avg_robust_acc')\n",
        "            fgsm_acc = base_stats.get('fgsm_acc') or base_stats.get('fgsm')\n",
        "\n",
        "            summary_rows.append({\n",
        "                'model_name': model_name,\n",
        "                'clean_acc': clean_acc,\n",
        "                'pgd_acc': pgd_acc,\n",
        "                'fgsm_acc': fgsm_acc,\n",
        "                'num_trainable_params': base_stats.get('num_trainable_params'),\n",
        "                'total_params': base_stats.get('total_params')\n",
        "            })\n",
        "\n",
        "        # Create DataFrame and save\n",
        "        results_df = pd.DataFrame(summary_rows)\n",
        "        results_df.to_csv(RESULTS_DIR / \"summary_results.csv\", index=False)\n",
        "        summary_clean = convert_np_types(results_df.to_dict(orient='records'))  # <-- convert here\n",
        "        json.dump(summary_clean, open(RESULTS_DIR / \"summary_results.json\", \"w\"), indent=2)\n",
        "        print(f\"Saved summary table to {RESULTS_DIR / 'summary_results.csv'} and JSON\")\n",
        "\n",
        "        # Generate the summary plots using your plotting wrappers\n",
        "        # try:\n",
        "        #     create_summary_plots(results_df, save_dir=RESULTS_DIR)\n",
        "        #     plot_individual_results(results_df, save_dir=RESULTS_DIR)\n",
        "        #     print(\"Summary plots generated and saved to\", RESULTS_DIR)\n",
        "        # except Exception as e:\n",
        "        #     print(\"Failed to generate summary plots:\", e)\n",
        "\n",
        "        # ----------------- End insertion -------------------------------------------------------------------------\n",
        "\n",
        "    print(\"\\nAll experiments completed.\")\n",
        "    return results_all_models\n",
        "\n",
        "# Run the ablation experiment\n",
        "results = run_experiment_ablation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOUuy8JobaZr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_dissertation_artifacts(results_csv=\"results/all_runs_results.csv\"):\n",
        "    df = pd.read_csv(results_csv)\n",
        "\n",
        "    # --- 1. Pareto Plot (Clean vs Mixed Robustness) ---\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(data=df, x='Clean_Acc', y='Mixed_Acc', hue='Model_Name', style='Config_Tag', s=100)\n",
        "    plt.title(\"Robustness-Accuracy Trade-off (Pareto Frontier)\")\n",
        "    plt.xlabel(\"Clean Data Accuracy\")\n",
        "    plt.ylabel(\"Mixed Attack Accuracy\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.savefig(\"results/pareto_frontier.png\")\n",
        "\n",
        "    # --- 2. Attack Success Rate Table ---\n",
        "    # ASR = (Clean Acc - Attack Acc) / Clean Acc\n",
        "    df['Synonym_ASR'] = (df['Clean_Acc'] - df['Synonym_Acc']) / df['Clean_Acc']\n",
        "    df['Char_ASR'] = (df['Clean_Acc'] - df['Character_Acc']) / df['Clean_Acc']\n",
        "\n",
        "    asr_table = df[['Model_Name', 'Config_Tag', 'Synonym_ASR', 'Char_ASR']]\n",
        "    asr_table.to_csv(\"results/attack_success_rates.csv\", index=False)\n",
        "\n",
        "    # --- 3. Efficiency Summary ---\n",
        "    efficiency_df = df[['Model_Name', 'Config_Tag', 'Avg_Latency', 'Mixed_Acc']]\n",
        "    print(\"\\n📊 Efficiency vs. Robustness Summary:\")\n",
        "    print(efficiency_df)\n",
        "\n",
        "    print(\"\\n✅ Artifacts generated in /results folder.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009c746b8da443c5b7fc807fa4eab37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2481f5718d644960b7d083b041076048",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fa38b76988c49128f9e3d1049ac4fd7",
            "value": 100
          }
        },
        "01833589d8174c0e9c24824381313436": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b6e2bc13144d8e83cc815b875a3823",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17d3d114fe354a46ab47d865e3b923de",
            "value": 100
          }
        },
        "01d3468e05cc4c7bb70e6b97025ba0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0261364a0de54921b8871c367b257d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "043c5005ab934728aaf5f0e0e14074fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0624abb3290f4a1dbec1d6550084f1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff666dfe54554d949fabfa92ae61d95b",
            "placeholder": "​",
            "style": "IPY_MODEL_09fa72dc6bf4460da1c28802527d4ad3",
            "value": " 100/100 [00:00&lt;00:00, 658.02it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "09fa72dc6bf4460da1c28802527d4ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ca2abbe590c47ee9807afb8487c7195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da10c6cc8274e13b082ccb95f498fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "117a92ccde0e46a7b527d6c3215a4004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e66e8d5cf29461a8c8f899ba60ef2d8",
              "IPY_MODEL_4f5ce4f7f9d243ae9d1aff9c934d1142",
              "IPY_MODEL_53e4d027d755416aa6cb90be3521a5a0"
            ],
            "layout": "IPY_MODEL_121e8adc40d74dbc9b7604835921f0ea"
          }
        },
        "121e8adc40d74dbc9b7604835921f0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138ca9b46c874f8fa9180a94e3d39972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17d3d114fe354a46ab47d865e3b923de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "187808e3801a49209c4866b39a53346a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efb562ee1e045d2b256eca5bf491776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2aacf4f22c4fe38a132b7c85b25c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f3b9fd2e9ee45c99a65d44efd137063": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4563a358d54541a3d81a414240906d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4d7bbffcef46a68c629d1809dd302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d5b2a758f04fba915fe004f62261ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2247b6a06ec3444289e3ffbda446c7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8808622d3634d59b6ed8cbb74c502cd",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c162f6a52f24ee7ab7a193ced8431f8",
            "value": 100
          }
        },
        "22923d6762f046e99ec8cb5c6017c851": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23baad196aad4b8aac49a1e78b08494f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2481f5718d644960b7d083b041076048": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26166625a3c14813b6f7f8961b5ba884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f21cb963a1bc41068b2ab6d392041ea9",
              "IPY_MODEL_8503e1d19cb34ab58a03e06e1c377f5c",
              "IPY_MODEL_8f0710d336ed4588aa73f8385e572252"
            ],
            "layout": "IPY_MODEL_043c5005ab934728aaf5f0e0e14074fc"
          }
        },
        "26e88827fe324cc08fac525dfd222bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42d25d9fa09b4ea2871284ef727d1881",
              "IPY_MODEL_70c95616a2d44fd39a73d6e06ea09d62",
              "IPY_MODEL_3a04f8cfbe5d4f20a1acf705d4b93af6"
            ],
            "layout": "IPY_MODEL_f3493971a3ec4fe89bd052e579849ab6"
          }
        },
        "28fbfaca8a35424ebf2866490d64af2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de4897d014042b1a1ec0f8cc21a3e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d5b2a758f04fba915fe004f62261ab",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2ee09607d8f4ceb9f3eb1480e65548e",
            "value": 100
          }
        },
        "30a988cf82e84a0f855f7b43488c5164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3218dce3db324ea483ca6024575942c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38a675053a6841df81aa112da7a5f50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a04f8cfbe5d4f20a1acf705d4b93af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ffdc2cd3154346aaf8e00cddf5fd45",
            "placeholder": "​",
            "style": "IPY_MODEL_7066896be3f241e1b9df52293412b449",
            "value": " 100/100 [00:00&lt;00:00, 332.03it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "3a4c4c80b54d4dfe8e0b447ca3ddeb00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb0c823a01b4d06b29a2da5255acdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bc9f7e6bd5a4cf0b0b6551acdf9755c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c555de0f1e14f66b94126b6c297356b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e61ba0d871146748adc7ea67804d3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66aae913dd094097953b3bef0b1ca5e1",
              "IPY_MODEL_4d0b873c198345fbba1478c8aa97aa54",
              "IPY_MODEL_f06358380d314ccdb4532c5611087234"
            ],
            "layout": "IPY_MODEL_beeae42109eb489398ec5c229bfc2401"
          }
        },
        "42d25d9fa09b4ea2871284ef727d1881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2625452a5a446798232e44bbea7fcc3",
            "placeholder": "​",
            "style": "IPY_MODEL_0da10c6cc8274e13b082ccb95f498fdb",
            "value": "Loading weights: 100%"
          }
        },
        "460cfefe390d4c209dc8b2ceea90cbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a708debe447d41f49c68bfb2117aed1f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea59b90d760f4d25814c44aea9e886c7",
            "value": "Loading weights: 100%"
          }
        },
        "4841187dc2e641a39b12fa6d107aa3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49504cae3b2448b4af0b82a14193a5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7dafe0b58f4a108f1b74113adabe69",
            "placeholder": "​",
            "style": "IPY_MODEL_138ca9b46c874f8fa9180a94e3d39972",
            "value": " 100/100 [00:00&lt;00:00, 505.83it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "496027e5e60842cb94b03fecadee185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d92c02c36fd4d969a354cde2d233ae5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bb0c823a01b4d06b29a2da5255acdaf",
            "value": 100
          }
        },
        "4b760e73afe14d5882f3c40ac44f6985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d00a0fbaecb4b79977220a078a6b0ba",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4d7bbffcef46a68c629d1809dd302b",
            "value": "Loading weights: 100%"
          }
        },
        "4c162f6a52f24ee7ab7a193ced8431f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d0b873c198345fbba1478c8aa97aa54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3b9fd2e9ee45c99a65d44efd137063",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6effd6612f314bbdad068d0ed28bed09",
            "value": 100
          }
        },
        "4f5ce4f7f9d243ae9d1aff9c934d1142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9170e05e7040bf9f94de49d1b111b5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5434974f9ce04e428b535a771ed340b1",
            "value": 100
          }
        },
        "50107308a63547feb1f721d03e93fcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_760e0badad1042c8991685544a202cc1",
            "placeholder": "​",
            "style": "IPY_MODEL_0261364a0de54921b8871c367b257d05",
            "value": "Loading weights: 100%"
          }
        },
        "53e4d027d755416aa6cb90be3521a5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d0582d832948d6b83ed0eaf095bf91",
            "placeholder": "​",
            "style": "IPY_MODEL_01d3468e05cc4c7bb70e6b97025ba0c9",
            "value": " 100/100 [00:00&lt;00:00, 246.92it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "5434974f9ce04e428b535a771ed340b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "565ce116571d4d5d98f61a9ed895b537": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a2f963c3ec4de4a0965d709f83a000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5818af3b25aa45c2acfc4972585e5814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638ee0856e6d4372a7c3a9eb0a4037f3",
            "placeholder": "​",
            "style": "IPY_MODEL_b77437d1688b4c43b021450d40bcd873",
            "value": "Loading weights: 100%"
          }
        },
        "5d92c02c36fd4d969a354cde2d233ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee54968a4ff4805a467b4fb399c04ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f4563a358d54541a3d81a414240906d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d89f8576c443a8aaa2a622b3958cf0",
            "value": 100
          }
        },
        "5f7c98a401514bfb96dd5a30c614d329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9524c9aec154071817a5dccf94336b3",
            "placeholder": "​",
            "style": "IPY_MODEL_38a675053a6841df81aa112da7a5f50d",
            "value": " 100/100 [00:00&lt;00:00, 602.43it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "60a5fa507ab94e929f4cd8c26945f77f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ffdc2cd3154346aaf8e00cddf5fd45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6379298fb54e447595e28d75c494d5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b87c6b27044fe49870779eeb94a34d",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcd821d146146e295d2b0273b95eaf6",
            "value": " 100/100 [00:00&lt;00:00, 349.09it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "638ee0856e6d4372a7c3a9eb0a4037f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b87c6b27044fe49870779eeb94a34d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66aae913dd094097953b3bef0b1ca5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1b43360ef004dea99f92e0e3be54f78",
            "placeholder": "​",
            "style": "IPY_MODEL_3218dce3db324ea483ca6024575942c6",
            "value": "Loading weights: 100%"
          }
        },
        "68f4f6ec1b7b4fec96cff5b3ebd9066a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e57b1714a44d2fb4b04a1dc24201fe",
            "placeholder": "​",
            "style": "IPY_MODEL_b789f013c08940c3a9d3b19d2456c750",
            "value": " 100/100 [00:00&lt;00:00, 383.96it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "69b8ce6f7ca7446ca4279d59e2243ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a605d59cd364e3284f4b1ac11d1fd2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9170e05e7040bf9f94de49d1b111b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2e2c3a947b4429969a38d92e91fe7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efb45b8cf8d4fe7a2b7e0952c9d3391": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6effd6612f314bbdad068d0ed28bed09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fa38b76988c49128f9e3d1049ac4fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7066896be3f241e1b9df52293412b449": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c95616a2d44fd39a73d6e06ea09d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab65d31746a41e9a024195ff9d5630a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fec2dda4d12f4371a6979dad010fb766",
            "value": 100
          }
        },
        "7188bad121b84373b8c8d315314a816b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5818af3b25aa45c2acfc4972585e5814",
              "IPY_MODEL_b85ea876297f4f1dbad2b4d2cbf2fa15",
              "IPY_MODEL_f7e4b70831204722becd8bcc7c5e50f0"
            ],
            "layout": "IPY_MODEL_22923d6762f046e99ec8cb5c6017c851"
          }
        },
        "760e0badad1042c8991685544a202cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc3c25fe5e54e7b8b21c041027a593e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c76c0bb2aef4232b77c9e2efddc05ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d00a0fbaecb4b79977220a078a6b0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4b20b7e6b4417ba2cfaad7185eee75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efbebc4a89624fba93067959ded6470c",
            "placeholder": "​",
            "style": "IPY_MODEL_f3573605504b48dcb8333e271ad21893",
            "value": "Loading weights: 100%"
          }
        },
        "81f1c3507b8d4a389170945d5f3e95cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8503e1d19cb34ab58a03e06e1c377f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ef30b925b74dcf94a8afe64a2411fc",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94b208da3c754628ad72f42e1cb6bbd2",
            "value": 100
          }
        },
        "8b7dafe0b58f4a108f1b74113adabe69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bfab1d4ff494753a63a0749f35d8892": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cbaeac1dc1e4d6d82affeaabdd1b73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b8eed724d64a6c9188b2f5b01a8c08",
            "placeholder": "​",
            "style": "IPY_MODEL_1f2aacf4f22c4fe38a132b7c85b25c43",
            "value": " 100/100 [00:00&lt;00:00, 456.03it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "8e66e8d5cf29461a8c8f899ba60ef2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c2ee7780f8401aa377a56e7a13d1f7",
            "placeholder": "​",
            "style": "IPY_MODEL_187808e3801a49209c4866b39a53346a",
            "value": "Loading weights: 100%"
          }
        },
        "8f0710d336ed4588aa73f8385e572252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81f1c3507b8d4a389170945d5f3e95cc",
            "placeholder": "​",
            "style": "IPY_MODEL_3c555de0f1e14f66b94126b6c297356b",
            "value": " 100/100 [00:00&lt;00:00, 506.11it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "904ef3caf03a4c4d9fd7d5aa63b09333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "909c51de2a9742b49e9803c854f36af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aebeef71f70a4a90b1274a3866d4c9a3",
              "IPY_MODEL_009c746b8da443c5b7fc807fa4eab37e",
              "IPY_MODEL_de669a8b011a4718ab79babe18f7c9c5"
            ],
            "layout": "IPY_MODEL_30a988cf82e84a0f855f7b43488c5164"
          }
        },
        "94b208da3c754628ad72f42e1cb6bbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97d0582d832948d6b83ed0eaf095bf91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9807b53008f4423eb8c92ff54547c8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb58ffdf6b54478baa6940a5e8174c13",
            "placeholder": "​",
            "style": "IPY_MODEL_fb4a2ecd04dd4567b17ef1ba75ce1f04",
            "value": "Loading weights: 100%"
          }
        },
        "99b8eed724d64a6c9188b2f5b01a8c08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee501e9849a49d495a2a1d4f962add4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d802c549e04055bc59827759c8d4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50fe74b2fa24d48bfa50cc183dca8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a708debe447d41f49c68bfb2117aed1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9524c9aec154071817a5dccf94336b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbd23acb22b439280cb4c0cfca2726d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adc7de544f054987b429fe97e7c85d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50107308a63547feb1f721d03e93fcdf",
              "IPY_MODEL_2de4897d014042b1a1ec0f8cc21a3e8c",
              "IPY_MODEL_0624abb3290f4a1dbec1d6550084f1f0"
            ],
            "layout": "IPY_MODEL_904ef3caf03a4c4d9fd7d5aa63b09333"
          }
        },
        "aebeef71f70a4a90b1274a3866d4c9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c76c0bb2aef4232b77c9e2efddc05ec",
            "placeholder": "​",
            "style": "IPY_MODEL_ec157ce6fa974b10a01ac7b03faefcf4",
            "value": "Loading weights: 100%"
          }
        },
        "b1b43360ef004dea99f92e0e3be54f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77437d1688b4c43b021450d40bcd873": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b789f013c08940c3a9d3b19d2456c750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b813a9e465534e19ab28c8fc815141f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b8ce6f7ca7446ca4279d59e2243ec0",
            "placeholder": "​",
            "style": "IPY_MODEL_0ca2abbe590c47ee9807afb8487c7195",
            "value": "Loading weights: 100%"
          }
        },
        "b85ea876297f4f1dbad2b4d2cbf2fa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a4c4c80b54d4dfe8e0b447ca3ddeb00",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0feab5e353a40719ae403ce185b2c27",
            "value": 100
          }
        },
        "b9caacc57ab94af7a1b808895326464b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be12176f31444999b0853525afa3df5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b760e73afe14d5882f3c40ac44f6985",
              "IPY_MODEL_f20e5dd191fa421db1f7f7f345a43129",
              "IPY_MODEL_d6d0f1d8016746cfa53d5a3209023665"
            ],
            "layout": "IPY_MODEL_57a2f963c3ec4de4a0965d709f83a000"
          }
        },
        "beeae42109eb489398ec5c229bfc2401": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf75b7c2a23c40dda64763b9e0ddfc6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d4b20b7e6b4417ba2cfaad7185eee75",
              "IPY_MODEL_2247b6a06ec3444289e3ffbda446c7d1",
              "IPY_MODEL_49504cae3b2448b4af0b82a14193a5c5"
            ],
            "layout": "IPY_MODEL_e09fb4098e6e45249884df91728be0b6"
          }
        },
        "c4e57b1714a44d2fb4b04a1dc24201fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6e638c143cf4433bf9d1f67a1ba1ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5190108478844a6a70bfc2a3e33398c",
              "IPY_MODEL_fc97d36e68b84e51b5c64fb7aec8c013",
              "IPY_MODEL_68f4f6ec1b7b4fec96cff5b3ebd9066a"
            ],
            "layout": "IPY_MODEL_eb89be4713094190bfc5b23a97156abe"
          }
        },
        "c8808622d3634d59b6ed8cbb74c502cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b6e2bc13144d8e83cc815b875a3823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb58ffdf6b54478baa6940a5e8174c13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0feab5e353a40719ae403ce185b2c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4d89f8576c443a8aaa2a622b3958cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5190108478844a6a70bfc2a3e33398c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a5fa507ab94e929f4cd8c26945f77f",
            "placeholder": "​",
            "style": "IPY_MODEL_23baad196aad4b8aac49a1e78b08494f",
            "value": "Loading weights: 100%"
          }
        },
        "d6d0f1d8016746cfa53d5a3209023665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc3c25fe5e54e7b8b21c041027a593e",
            "placeholder": "​",
            "style": "IPY_MODEL_28fbfaca8a35424ebf2866490d64af2c",
            "value": " 100/100 [00:00&lt;00:00, 434.16it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "d7d1ee9b2ba84c05a0e55d6f4e5c37c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b813a9e465534e19ab28c8fc815141f8",
              "IPY_MODEL_5ee54968a4ff4805a467b4fb399c04ce",
              "IPY_MODEL_5f7c98a401514bfb96dd5a30c614d329"
            ],
            "layout": "IPY_MODEL_8bfab1d4ff494753a63a0749f35d8892"
          }
        },
        "dab65d31746a41e9a024195ff9d5630a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de669a8b011a4718ab79babe18f7c9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2e2c3a947b4429969a38d92e91fe7f",
            "placeholder": "​",
            "style": "IPY_MODEL_b9caacc57ab94af7a1b808895326464b",
            "value": " 100/100 [00:00&lt;00:00, 393.76it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "e09fb4098e6e45249884df91728be0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ee09607d8f4ceb9f3eb1480e65548e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7c2ee7780f8401aa377a56e7a13d1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea59b90d760f4d25814c44aea9e886c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb89be4713094190bfc5b23a97156abe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc250e7e4974f94bdb4f9e13ce62aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec157ce6fa974b10a01ac7b03faefcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec39f1c76ddc48ebb61757f4941479c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9807b53008f4423eb8c92ff54547c8de",
              "IPY_MODEL_496027e5e60842cb94b03fecadee185d",
              "IPY_MODEL_8cbaeac1dc1e4d6d82affeaabdd1b73a"
            ],
            "layout": "IPY_MODEL_f0f430ef3ad6491b90d27424e5c72142"
          }
        },
        "efbebc4a89624fba93067959ded6470c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06358380d314ccdb4532c5611087234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565ce116571d4d5d98f61a9ed895b537",
            "placeholder": "​",
            "style": "IPY_MODEL_4841187dc2e641a39b12fa6d107aa3f4",
            "value": " 100/100 [00:00&lt;00:00, 386.16it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "f0f430ef3ad6491b90d27424e5c72142": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20e5dd191fa421db1f7f7f345a43129": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee501e9849a49d495a2a1d4f962add4",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebc250e7e4974f94bdb4f9e13ce62aa9",
            "value": 100
          }
        },
        "f21cb963a1bc41068b2ab6d392041ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc9f7e6bd5a4cf0b0b6551acdf9755c",
            "placeholder": "​",
            "style": "IPY_MODEL_a50fe74b2fa24d48bfa50cc183dca8c2",
            "value": "Loading weights: 100%"
          }
        },
        "f2625452a5a446798232e44bbea7fcc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3493971a3ec4fe89bd052e579849ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3573605504b48dcb8333e271ad21893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e4b70831204722becd8bcc7c5e50f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a605d59cd364e3284f4b1ac11d1fd2c",
            "placeholder": "​",
            "style": "IPY_MODEL_1efb562ee1e045d2b256eca5bf491776",
            "value": " 100/100 [00:00&lt;00:00, 231.72it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]"
          }
        },
        "f8ef30b925b74dcf94a8afe64a2411fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa69fa5c5934a628a44f5bf2a5741b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_460cfefe390d4c209dc8b2ceea90cbe6",
              "IPY_MODEL_01833589d8174c0e9c24824381313436",
              "IPY_MODEL_6379298fb54e447595e28d75c494d5e7"
            ],
            "layout": "IPY_MODEL_6efb45b8cf8d4fe7a2b7e0952c9d3391"
          }
        },
        "fb4a2ecd04dd4567b17ef1ba75ce1f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc97d36e68b84e51b5c64fb7aec8c013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d802c549e04055bc59827759c8d4f2",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abbd23acb22b439280cb4c0cfca2726d",
            "value": 100
          }
        },
        "fdcd821d146146e295d2b0273b95eaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fec2dda4d12f4371a6979dad010fb766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff666dfe54554d949fabfa92ae61d95b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
